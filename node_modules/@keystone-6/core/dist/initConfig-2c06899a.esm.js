import _objectSpread from '@babel/runtime/helpers/esm/objectSpread2';
import pLimit from 'p-limit';
import { g as getGqlNames } from './core-c6bc4160.esm.js';
import { Q as QueryMode, f as fieldType, o as orderDirectionEnum } from './sqlite-11f2ae03.esm.js';
import _objectWithoutProperties from '@babel/runtime/helpers/esm/objectWithoutProperties';
import { g as graphqlBoundToKeystoneContext, J as JSON$1 } from './graphql-ts-schema-ecd3b4c2.esm.js';
import { isInputObjectType, GraphQLString, executeSync, parse, GraphQLUnionType, GraphQLScalarType, GraphQLNonNull, GraphQLSchema, validate, execute, GraphQLList, print, graphql as graphql$1 } from 'graphql';
import { h as humanize, e as extensionError, a as accessReturnError, b as accessDeniedError, u as userInputError, v as validationFailureError, r as resolverError, c as relationshipError } from './graphql-errors-dd21b092.esm.js';
import * as path from 'path';
import path__default from 'path';
import { promisify } from 'util';
import fs__default from 'fs-extra';
import resolve from 'resolve';
import { walk as walk$1 } from '@nodelib/fs.walk';
import hashString from '@emotion/hash';
import { s as staticAdminMetaQuery } from './admin-meta-graphql-4f7bd0cb.esm.js';
import '@graphql-tools/schema';
import { bindGraphQLSchemaAPIToContext } from '@graphql-ts/schema';
import _classPrivateFieldInitSpec from '@babel/runtime/helpers/esm/classPrivateFieldInitSpec';
import _classPrivateFieldGet from '@babel/runtime/helpers/esm/classPrivateFieldGet';
import _classPrivateFieldSet from '@babel/runtime/helpers/esm/classPrivateFieldSet';
import { m as mapUniqueWhereToWhere, r as resolveWhereInput, a as runWithPrisma, b as resolveUniqueWhereInput, i as isRejected, c as isFulfilled, g as getOperationAccess, d as getAccessFilters, e as getWriteLimit, f as checkFilterOrderAccess, h as getDBFieldKeyForFieldOnMultiField, p as promiseAllRejectWithAllErrors, j as findOne, k as findMany, l as count, n as getVariablesForGraphQLField, o as executeGraphQLFieldToRootVal, q as initialiseLists, s as setWriteLimit } from './types-for-lists-9f8f5d4c.esm.js';
import _defineProperty from '@babel/runtime/helpers/esm/defineProperty';
import { field, object } from '@graphql-ts/schema/api-with-context';
import { arg, nonNull, list, inputObject, Int, Boolean, ID } from '@graphql-ts/schema/api-without-context';
import { v4, validate as validate$1 } from 'uuid';
import fromBuffer from 'image-type';
import imageSize from 'image-size';
import { parseImageRef } from '../fields/types/image/utils/dist/keystone-6-core-fields-types-image-utils.esm.js';
import crypto from 'crypto';
import { pipeline } from 'stream';
import filenamify from 'filenamify';
import slugify from '@sindresorhus/slugify';
import { parseFileRef } from '../fields/types/file/utils/dist/keystone-6-core-fields-types-file-utils.esm.js';
import fetch from 'node-fetch';
import FormData from 'form-data';
import { isCuid } from 'cuid';
import { p as packagePath } from './package-path-5ec371a3.esm.js';

function createAdminMeta(config, initialisedLists) {
  const {
    ui,
    lists,
    session
  } = config;
  const adminMetaRoot = {
    enableSessionItem: (ui === null || ui === void 0 ? void 0 : ui.enableSessionItem) || false,
    enableSignout: session !== undefined,
    listsByKey: {},
    lists: [],
    views: []
  };
  const omittedLists = [];

  for (const [key, list] of Object.entries(initialisedLists)) {
    var _ref, _listConfig$ui, _listConfig$ui2, _listConfig$ui2$listV, _ref2, _listConfig$ui$descri, _listConfig$ui3, _listConfig$ui$listVi, _listConfig$ui4, _listConfig$ui4$listV, _ref3, _listConfig$ui5, _listConfig$ui5$listV;

    const listConfig = lists[key];

    if (list.graphql.isEnabled.query === false) {
      // If graphql querying is disabled on the list,
      // push the key into the ommittedLists array for use further down in the procedure and skip.
      omittedLists.push(key);
      continue;
    } // Default the labelField to `name`, `label`, or `title` if they exist; otherwise fall back to `id`


    const labelField = (_ref = (_listConfig$ui = listConfig.ui) === null || _listConfig$ui === void 0 ? void 0 : _listConfig$ui.labelField) !== null && _ref !== void 0 ? _ref : listConfig.fields.label ? 'label' : listConfig.fields.name ? 'name' : listConfig.fields.title ? 'title' : 'id';
    let initialColumns;

    if ((_listConfig$ui2 = listConfig.ui) !== null && _listConfig$ui2 !== void 0 && (_listConfig$ui2$listV = _listConfig$ui2.listView) !== null && _listConfig$ui2$listV !== void 0 && _listConfig$ui2$listV.initialColumns) {
      // If they've asked for a particular thing, give them that thing
      initialColumns = listConfig.ui.listView.initialColumns;
    } else {
      // Otherwise, we'll start with the labelField on the left and then add
      // 2 more fields to the right of that. We don't include the 'id' field
      // unless it happened to be the labelField
      initialColumns = [labelField, ...Object.keys(list.fields).filter(fieldKey => list.fields[fieldKey].graphql.isEnabled.read).filter(fieldKey => fieldKey !== labelField).filter(fieldKey => fieldKey !== 'id')].slice(0, 3);
    }

    adminMetaRoot.listsByKey[key] = {
      key,
      labelField,
      description: (_ref2 = (_listConfig$ui$descri = (_listConfig$ui3 = listConfig.ui) === null || _listConfig$ui3 === void 0 ? void 0 : _listConfig$ui3.description) !== null && _listConfig$ui$descri !== void 0 ? _listConfig$ui$descri : listConfig.description) !== null && _ref2 !== void 0 ? _ref2 : null,
      label: list.adminUILabels.label,
      singular: list.adminUILabels.singular,
      plural: list.adminUILabels.plural,
      path: list.adminUILabels.path,
      fields: [],
      pageSize: (_listConfig$ui$listVi = (_listConfig$ui4 = listConfig.ui) === null || _listConfig$ui4 === void 0 ? void 0 : (_listConfig$ui4$listV = _listConfig$ui4.listView) === null || _listConfig$ui4$listV === void 0 ? void 0 : _listConfig$ui4$listV.pageSize) !== null && _listConfig$ui$listVi !== void 0 ? _listConfig$ui$listVi : 50,
      initialColumns,
      initialSort: (_ref3 = (_listConfig$ui5 = listConfig.ui) === null || _listConfig$ui5 === void 0 ? void 0 : (_listConfig$ui5$listV = _listConfig$ui5.listView) === null || _listConfig$ui5$listV === void 0 ? void 0 : _listConfig$ui5$listV.initialSort) !== null && _ref3 !== void 0 ? _ref3 : null,
      // TODO: probably remove this from the GraphQL schema and here
      itemQueryName: key,
      listQueryName: list.pluralGraphQLName
    };
    adminMetaRoot.lists.push(adminMetaRoot.listsByKey[key]);
  }

  let uniqueViewCount = -1;
  const stringViewsToIndex = {};

  function getViewId(view) {
    if (stringViewsToIndex[view] !== undefined) {
      return stringViewsToIndex[view];
    }

    uniqueViewCount++;
    stringViewsToIndex[view] = uniqueViewCount;
    adminMetaRoot.views.push(view);
    return uniqueViewCount;
  } // Populate .fields array


  for (const [key, list] of Object.entries(initialisedLists)) {
    var _config$lists$key$ui$, _config$lists$key$ui, _config$lists$key$ui2;

    if (omittedLists.includes(key)) continue;
    const searchFields = new Set((_config$lists$key$ui$ = (_config$lists$key$ui = config.lists[key].ui) === null || _config$lists$key$ui === void 0 ? void 0 : _config$lists$key$ui.searchFields) !== null && _config$lists$key$ui$ !== void 0 ? _config$lists$key$ui$ : []);

    if (searchFields.has('id')) {
      throw new Error(`The ui.searchFields option on the ${key} list includes 'id'. Lists can always be searched by an item's id so it must not be specified as a search field`);
    }

    const whereInputFields = list.types.where.graphQLType.getFields();
    const possibleSearchFields = new Map();

    for (const fieldKey of Object.keys(list.fields)) {
      var _whereInputFields$fie, _fieldFilterFields$co;

      const filterType = (_whereInputFields$fie = whereInputFields[fieldKey]) === null || _whereInputFields$fie === void 0 ? void 0 : _whereInputFields$fie.type;
      const fieldFilterFields = isInputObjectType(filterType) ? filterType.getFields() : undefined;

      if ((fieldFilterFields === null || fieldFilterFields === void 0 ? void 0 : (_fieldFilterFields$co = fieldFilterFields.contains) === null || _fieldFilterFields$co === void 0 ? void 0 : _fieldFilterFields$co.type) === GraphQLString) {
        var _fieldFilterFields$mo;

        possibleSearchFields.set(fieldKey, (fieldFilterFields === null || fieldFilterFields === void 0 ? void 0 : (_fieldFilterFields$mo = fieldFilterFields.mode) === null || _fieldFilterFields$mo === void 0 ? void 0 : _fieldFilterFields$mo.type) === QueryMode.graphQLType ? 'insensitive' : 'default');
      }
    }

    if (((_config$lists$key$ui2 = config.lists[key].ui) === null || _config$lists$key$ui2 === void 0 ? void 0 : _config$lists$key$ui2.searchFields) === undefined) {
      const labelField = adminMetaRoot.listsByKey[key].labelField;

      if (possibleSearchFields.has(labelField)) {
        searchFields.add(labelField);
      }
    }

    for (const [fieldKey, field] of Object.entries(list.fields)) {
      var _possibleSearchFields, _field$label, _field$ui;

      // If the field is a relationship field and is related to an omitted list, skip.
      if (field.dbField.kind === 'relation' && omittedLists.includes(field.dbField.list)) continue; // FIXME: Disabling this entirely for now until the Admin UI can properly
      // handle `omit: ['read']` correctly.

      if (field.graphql.isEnabled.read === false) continue;
      let search = searchFields.has(fieldKey) ? (_possibleSearchFields = possibleSearchFields.get(fieldKey)) !== null && _possibleSearchFields !== void 0 ? _possibleSearchFields : null : null;

      if (searchFields.has(fieldKey) && search === null) {
        throw new Error(`The ui.searchFields option on the ${key} list includes '${fieldKey}' but that field doesn't have a contains filter that accepts a GraphQL String`);
      }

      adminMetaRoot.listsByKey[key].fields.push({
        label: (_field$label = field.label) !== null && _field$label !== void 0 ? _field$label : humanize(fieldKey),
        viewsIndex: getViewId(field.views),
        customViewsIndex: ((_field$ui = field.ui) === null || _field$ui === void 0 ? void 0 : _field$ui.views) === undefined ? null : getViewId(field.ui.views),
        fieldMeta: null,
        path: fieldKey,
        listKey: key,
        search
      });
    }
  } // we do this seperately to the above so that fields can check other fields to validate their config or etc.
  // (ofc they won't necessarily be able to see other field's fieldMeta)


  for (const [key, list] of Object.entries(initialisedLists)) {
    if (list.graphql.isEnabled.query === false) continue;

    for (const fieldMetaRootVal of adminMetaRoot.listsByKey[key].fields) {
      var _list$fields$fieldMet, _list$fields$fieldMet2, _list$fields$fieldMet3;

      const dbField = list.fields[fieldMetaRootVal.path].dbField; // If the field is a relationship field and is related to an omitted list, skip.

      if (dbField.kind === 'relation' && omittedLists.includes(dbField.list)) {
        continue;
      }

      fieldMetaRootVal.fieldMeta = (_list$fields$fieldMet = (_list$fields$fieldMet2 = (_list$fields$fieldMet3 = list.fields[fieldMetaRootVal.path]).getAdminMeta) === null || _list$fields$fieldMet2 === void 0 ? void 0 : _list$fields$fieldMet2.call(_list$fields$fieldMet3, adminMetaRoot)) !== null && _list$fields$fieldMet !== void 0 ? _list$fields$fieldMet : null;
    }
  }

  return adminMetaRoot;
}

function serializePathForImport(path) {
  // JSON.stringify is important here because it will escape windows style paths(and any thing else that might potentially be in there)
  return JSON.stringify(path // Next is unhappy about imports that include .ts/tsx in them because TypeScript is unhappy with them because when doing a TypeScript compilation with tsc, the imports won't be written so they would be wrong there
  .replace(/\.tsx?$/, '').replace(new RegExp(`\\${path__default.sep}`, 'g'), '/'));
}

const appTemplate = (adminMetaRootVal, graphQLSchema, _ref, apiPath, isLiveReload) => {
  let {
    configFileExists,
    projectAdminPath
  } = _ref;
  const result = executeSync({
    document: staticAdminMetaQuery,
    schema: graphQLSchema,
    contextValue: {
      isAdminUIBuildProcess: true
    }
  });

  if (result.errors) {
    throw result.errors[0];
  }

  const {
    adminMeta
  } = result.data.keystone;
  const adminMetaQueryResultHash = hashString(JSON.stringify(adminMeta));
  const allViews = adminMetaRootVal.views.map(views => {
    // webpack/next for some reason _sometimes_ adds a query parameter to the return of require.resolve
    // because it does it _sometimes_, we have to remove it so that during live reloading
    // we're not constantly doing builds because the query param is there and then it's not and then it is and so on
    views = views.replace(/\?[A-Za-z0-9]+$/, ''); // webpack/next adds (api)/ to the return of require.resolve

    views = views.replace(/^\(api\)\//, ''); // during a live reload, we'll have paths from a webpack compilation which will make the paths
    // that __dirname/__filename/require.resolve return relative to the webpack's "context" option
    // which for Next, it's set to the directory of the Next project which is projectAdminPath here.
    // so to get absolute paths, we need to resolve them relative to the projectAdminPath
    // generally though, relative paths are problematic because
    // we don't know where to resolve them from so we disallow them
    // we're assuming that the relative paths we get
    // of course, this isn't necessarily true but it's kinda the best we can do
    // this means that if someone writes a relative path as a view during live reloading
    // they'll get a more confusing error than they would get at startup

    if (isLiveReload) {
      views = path__default.resolve(projectAdminPath, views);
    } else if (!path__default.isAbsolute(views)) {
      throw new Error(`Field views must be absolute paths, but ${JSON.stringify(views)} was provided. Use path.join(__dirname, './relative/path') or require.resolve('./relative/path') to get an absolute path.`);
    }

    const viewPath = path__default.relative(path__default.join(projectAdminPath, 'pages'), views);
    return serializePathForImport(viewPath);
  }); // -- TEMPLATE START

  return `import { getApp } from '@keystone-6/core/___internal-do-not-use-will-break-in-patch/admin-ui/pages/App';

${allViews.map((views, i) => `import * as view${i} from ${views};`).join('\n')}

${configFileExists ? `import * as adminConfig from "../../../admin/config";` : 'var adminConfig = {};'}

export default getApp({
  lazyMetadataQuery: ${JSON.stringify(getLazyMetadataQuery(graphQLSchema, adminMeta))},
  fieldViews: [${allViews.map((_, i) => `view${i}`)}],
  adminMetaHash: "${adminMetaQueryResultHash}",
  adminConfig: adminConfig,
  apiPath: "${apiPath}",
});
`; // -- TEMPLATE END
};

function getLazyMetadataQuery(graphqlSchema, adminMeta) {
  const selections = parse(`fragment x on y {
    keystone {
      adminMeta {
        lists {
          key
          isHidden
          fields {
            path
            createView {
              fieldMode
            }
          }
        }
      }
    }
  }`).definitions[0].selectionSet.selections;
  const queryType = graphqlSchema.getQueryType();

  if (queryType) {
    const getListByKey = name => adminMeta.lists.find(_ref2 => {
      let {
        key
      } = _ref2;
      return key === name;
    });

    const fields = queryType.getFields();

    if (fields['authenticatedItem'] !== undefined) {
      const authenticatedItemType = fields['authenticatedItem'].type;

      if (!(authenticatedItemType instanceof GraphQLUnionType) || authenticatedItemType.name !== 'AuthenticatedItem') {
        throw new Error(`The type of Query.authenticatedItem must be a type named AuthenticatedItem and be a union of types that refer to Keystone lists but it is "${authenticatedItemType.toString()}"`);
      }

      for (const type of authenticatedItemType.getTypes()) {
        const fields = type.getFields();
        const list = getListByKey(type.name);

        if (list === undefined) {
          throw new Error(`All members of the AuthenticatedItem union must refer to Keystone lists but "${type.name}" is in the AuthenticatedItem union but is not a Keystone list`);
        }

        let labelGraphQLField = fields[list.labelField];

        if (labelGraphQLField === undefined) {
          throw new Error(`The labelField for the list "${list.key}" is "${list.labelField}" but the GraphQL type does not have a field named "${list.labelField}"`);
        }

        let labelGraphQLFieldType = labelGraphQLField.type;

        if (labelGraphQLFieldType instanceof GraphQLNonNull) {
          labelGraphQLFieldType = labelGraphQLFieldType.ofType;
        }

        if (!(labelGraphQLFieldType instanceof GraphQLScalarType)) {
          throw new Error(`Label fields must be scalar GraphQL types but the labelField "${list.labelField}" on the list "${list.key}" is not a scalar type`);
        }

        const requiredArgs = labelGraphQLField.args.filter(arg => arg.defaultValue === undefined && arg.type instanceof GraphQLNonNull);

        if (requiredArgs.length) {
          throw new Error(`Label fields must have no required arguments but the labelField "${list.labelField}" on the list "${list.key}" has a required argument "${requiredArgs[0].name}"`);
        }
      }

      selections.push({
        kind: 'Field',
        name: {
          kind: 'Name',
          value: 'authenticatedItem'
        },
        selectionSet: {
          kind: 'SelectionSet',
          selections: authenticatedItemType.getTypes().map(_ref3 => {
            let {
              name
            } = _ref3;
            return {
              kind: 'InlineFragment',
              typeCondition: {
                kind: 'NamedType',
                name: {
                  kind: 'Name',
                  value: name
                }
              },
              selectionSet: {
                kind: 'SelectionSet',
                selections: [{
                  kind: 'Field',
                  name: {
                    kind: 'Name',
                    value: 'id'
                  }
                }, {
                  kind: 'Field',
                  name: {
                    kind: 'Name',
                    value: getListByKey(name).labelField
                  }
                }]
              }
            };
          })
        }
      });
    }
  } // We're returning the complete query AST here for explicit-ness


  return {
    kind: 'Document',
    definitions: [{
      kind: 'OperationDefinition',
      operation: 'query',
      selectionSet: {
        kind: 'SelectionSet',
        selections
      }
    }]
  };
}

const homeTemplate = `export { HomePage as default } from '@keystone-6/core/___internal-do-not-use-will-break-in-patch/admin-ui/pages/HomePage';
`;

const listTemplate = listKey => `import { getListPage } from '@keystone-6/core/___internal-do-not-use-will-break-in-patch/admin-ui/pages/ListPage';

export default getListPage(${JSON.stringify({
  listKey
})});
`;

const itemTemplate = listKey => `import { getItemPage } from '@keystone-6/core/___internal-do-not-use-will-break-in-patch/admin-ui/pages/ItemPage';

export default getItemPage(${JSON.stringify({
  listKey
})})
`;

const apiTemplate = `
import keystoneConfig from '../../../../keystone';
import { initConfig, createSystem, createApolloServerMicro } from '@keystone-6/core/system';
import { PrismaClient } from '.prisma/client';

const initializedKeystoneConfig = initConfig(keystoneConfig);
const { graphQLSchema, keystone, createContext } = createSystem(initializedKeystoneConfig, 'none', PrismaClient);
const apolloServer = createApolloServerMicro({
  graphQLSchema,
  createContext,
  sessionStrategy: initializedKeystoneConfig.session ? initializedKeystoneConfig.session() : undefined,
  graphqlConfig: initializedKeystoneConfig.graphql,
  connectionPromise: keystone.connect(),
});

export const config = {
  api: {
    bodyParser: false,
  },
};
export default apolloServer.createHandler({ path: initializedKeystoneConfig.graphql?.path || '/api/graphql' });
`;

const noAccessTemplate = session => `import { getNoAccessPage } from '@keystone-6/core/___internal-do-not-use-will-break-in-patch/admin-ui/pages/NoAccessPage';

export default getNoAccessPage(${JSON.stringify({
  sessionsEnabled: !!session
})})
`;

const pkgDir = path.dirname(require.resolve('@keystone-6/core/package.json'));
const writeAdminFiles = (config, graphQLSchema, adminMeta, configFileExists, projectAdminPath, isLiveReload) => {
  var _config$experimental, _config$graphql, _config$graphql2, _config$experimental2, _config$graphql3;

  if ((_config$experimental = config.experimental) !== null && _config$experimental !== void 0 && _config$experimental.enableNextJsGraphqlApiEndpoint && (_config$graphql = config.graphql) !== null && _config$graphql !== void 0 && _config$graphql.path && !config.graphql.path.startsWith('/api/')) {
    throw new Error('config.graphql.path must start with "/api/" when using config.experimental.enableNextJsGraphqlApiEndpoint');
  }

  return [...['next.config.js', 'tsconfig.json'].map(outputPath => ({
    mode: 'copy',
    inputPath: path.join(pkgDir, 'static', outputPath),
    outputPath
  })), {
    mode: 'copy',
    inputPath: path.join(pkgDir, 'static', 'favicon.ico'),
    outputPath: 'public/favicon.ico'
  }, {
    mode: 'write',
    src: noAccessTemplate(config.session),
    outputPath: 'pages/no-access.js'
  }, {
    mode: 'write',
    src: appTemplate(adminMeta, graphQLSchema, {
      configFileExists,
      projectAdminPath
    }, ((_config$graphql2 = config.graphql) === null || _config$graphql2 === void 0 ? void 0 : _config$graphql2.path) || '/api/graphql', isLiveReload),
    outputPath: 'pages/_app.js'
  }, {
    mode: 'write',
    src: homeTemplate,
    outputPath: 'pages/index.js'
  }, ...adminMeta.lists.map(_ref => {
    let {
      path,
      key
    } = _ref;
    return {
      mode: 'write',
      src: listTemplate(key),
      outputPath: `pages/${path}/index.js`
    };
  }), ...adminMeta.lists.map(_ref2 => {
    let {
      path,
      key
    } = _ref2;
    return {
      mode: 'write',
      src: itemTemplate(key),
      outputPath: `pages/${path}/[id].js`
    };
  }), ...((_config$experimental2 = config.experimental) !== null && _config$experimental2 !== void 0 && _config$experimental2.enableNextJsGraphqlApiEndpoint ? [{
    mode: 'write',
    src: apiTemplate,
    outputPath: `pages/${((_config$graphql3 = config.graphql) === null || _config$graphql3 === void 0 ? void 0 : _config$graphql3.path) || '/api/graphql'}.js`
  }] : [])];
};

const walk = promisify(walk$1);

function getDoesAdminConfigExist() {
  try {
    const configPath = path__default.join(process.cwd(), 'admin', 'config');
    resolve.sync(configPath, {
      extensions: ['.ts', '.tsx', '.js'],
      preserveSymlinks: false
    });
    return true;
  } catch (err) {
    if (err.code === 'MODULE_NOT_FOUND') {
      return false;
    }

    throw err;
  }
}

async function writeAdminFile(file, projectAdminPath) {
  const outputFilename = path__default.join(projectAdminPath, file.outputPath);

  if (file.mode === 'copy') {
    if (!path__default.isAbsolute(file.inputPath)) {
      throw new Error(`An inputPath of "${file.inputPath}" was provided to copy but inputPaths must be absolute`);
    }

    await fs__default.ensureDir(path__default.dirname(outputFilename)); // TODO: should we use copyFile or copy?

    await fs__default.copyFile(file.inputPath, outputFilename);
  }

  let content;

  try {
    content = await fs__default.readFile(outputFilename, 'utf8');
  } catch (err) {
    if (err.code !== 'ENOENT') {
      throw err;
    }
  }

  if (file.mode === 'write' && content !== file.src) {
    await fs__default.outputFile(outputFilename, file.src);
  }

  return path__default.normalize(outputFilename);
}
const pageExtensions = new Set(['.js', '.jsx', '.ts', '.tsx']);
const generateAdminUI = async (config, graphQLSchema, adminMeta, projectAdminPath, isLiveReload) => {
  var _config$ui$getAdditio, _config$ui, _config$ui$getAdditio2;

  // when we're not doing a live reload, we want to clear everything out except the .next directory (not the .next directory because it has caches)
  // so that at least every so often, we'll clear out anything that the deleting we do during live reloads doesn't (should just be directories)
  if (!isLiveReload) {
    const dir = await fs__default.readdir(projectAdminPath).catch(err => {
      if (err.code === 'ENOENT') {
        return [];
      }

      throw err;
    });
    await Promise.all(dir.map(x => {
      if (x === '.next') return;
      return fs__default.remove(path__default.join(projectAdminPath, x));
    }));
  } // Write out the files configured by the user


  const userFiles = (_config$ui$getAdditio = (_config$ui = config.ui) === null || _config$ui === void 0 ? void 0 : (_config$ui$getAdditio2 = _config$ui.getAdditionalFiles) === null || _config$ui$getAdditio2 === void 0 ? void 0 : _config$ui$getAdditio2.map(x => x(config))) !== null && _config$ui$getAdditio !== void 0 ? _config$ui$getAdditio : [];
  const userFilesToWrite = (await Promise.all(userFiles)).flat();
  const savedFiles = await Promise.all(userFilesToWrite.map(file => writeAdminFile(file, projectAdminPath)));
  const uniqueFiles = new Set(savedFiles); // Write out the built-in admin UI files. Don't overwrite any user-defined pages.

  const configFileExists = getDoesAdminConfigExist();
  let adminFiles = writeAdminFiles(config, graphQLSchema, adminMeta, configFileExists, projectAdminPath, isLiveReload); // Add files to pages/ which point to any files which exist in admin/pages

  const adminConfigDir = path__default.join(process.cwd(), 'admin');
  const userPagesDir = path__default.join(adminConfigDir, 'pages');
  let userPagesEntries = [];

  try {
    userPagesEntries = await walk(userPagesDir, {
      entryFilter: entry => entry.dirent.isFile() && pageExtensions.has(path__default.extname(entry.name))
    });
  } catch (err) {
    if (err.code !== 'ENOENT') {
      throw err;
    }
  }

  for (const {
    path
  } of userPagesEntries) {
    const outputFilename = path__default.relative(adminConfigDir, path);
    const importPath = path__default.relative(path__default.dirname(path__default.join(projectAdminPath, outputFilename)), path);
    const serializedImportPath = serializePathForImport(importPath);
    adminFiles.push({
      mode: 'write',
      outputPath: outputFilename,
      src: `export { default } from ${serializedImportPath}`
    });
  }

  adminFiles = adminFiles.filter(x => !uniqueFiles.has(path__default.normalize(path__default.join(projectAdminPath, x.outputPath))));
  await Promise.all(adminFiles.map(file => writeAdminFile(file, projectAdminPath))); // Because Next will re-compile things (or at least check things and log a bunch of stuff)
  // if we delete pages and then re-create them, we want to avoid that when live reloading
  // so we only delete things that shouldn't exist anymore
  // this won't clear out empty directories, this is fine since:
  // - they won't create pages in Admin UI which is really what this deleting is about avoiding
  // - we'll remove them when the user restarts the process

  if (isLiveReload) {
    const ignoredDir = path__default.resolve(projectAdminPath, '.next');
    const ignoredFiles = new Set([...adminFiles.map(x => x.outputPath), ...uniqueFiles, 'next-env.d.ts', 'pages/api/__keystone_api_build.js'].map(x => path__default.resolve(projectAdminPath, x)));
    const entries = await walk(projectAdminPath, {
      deepFilter: entry => entry.path !== ignoredDir,
      entryFilter: entry => entry.dirent.isFile() && !ignoredFiles.has(entry.path)
    });
    await Promise.all(entries.map(entry => fs__default.remove(entry.path)));
  }
};

const graphql = _objectSpread(_objectSpread({}, graphqlBoundToKeystoneContext), bindGraphQLSchemaAPIToContext());

function getAdminMetaSchema(_ref) {
  var _config$ui$isAccessAl, _config$ui;

  let {
    config,
    lists,
    adminMeta: adminMetaRoot
  } = _ref;
  const isAccessAllowed = (_config$ui$isAccessAl = (_config$ui = config.ui) === null || _config$ui === void 0 ? void 0 : _config$ui.isAccessAllowed) !== null && _config$ui$isAccessAl !== void 0 ? _config$ui$isAccessAl : config.session === undefined ? undefined : _ref2 => {
    let {
      session
    } = _ref2;
    return session !== undefined;
  };
  const jsonScalar = JSON$1;
  const KeystoneAdminUIFieldMeta = graphql.object()({
    name: 'KeystoneAdminUIFieldMeta',
    fields: {
      path: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      label: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      isOrderable: graphql.field({
        type: graphql.nonNull(graphql.Boolean),

        resolve(rootVal, args, context) {
          var _lists$rootVal$listKe;

          if ('isAdminUIBuildProcess' in context) {
            throw new Error('KeystoneAdminUIFieldMeta.isOrderable cannot be resolved during the build process');
          }

          if (!((_lists$rootVal$listKe = lists[rootVal.listKey].fields[rootVal.path].input) !== null && _lists$rootVal$listKe !== void 0 && _lists$rootVal$listKe.orderBy)) {
            return false;
          }

          const isOrderable = lists[rootVal.listKey].fields[rootVal.path].graphql.isEnabled.orderBy;

          if (typeof isOrderable === 'function') {
            return isOrderable({
              context,
              fieldKey: rootVal.path,
              listKey: rootVal.listKey,
              session: context.session
            });
          }

          return isOrderable;
        }

      }),
      isFilterable: graphql.field({
        type: graphql.nonNull(graphql.Boolean),

        resolve(rootVal, args, context) {
          var _lists$rootVal$listKe2;

          if ('isAdminUIBuildProcess' in context) {
            throw new Error('KeystoneAdminUIFieldMeta.isOrderable cannot be resolved during the build process');
          }

          if (!((_lists$rootVal$listKe2 = lists[rootVal.listKey].fields[rootVal.path].input) !== null && _lists$rootVal$listKe2 !== void 0 && _lists$rootVal$listKe2.where)) {
            return false;
          }

          const isFilterable = lists[rootVal.listKey].fields[rootVal.path].graphql.isEnabled.filter;

          if (typeof isFilterable === 'function') {
            return isFilterable({
              context,
              fieldKey: rootVal.path,
              listKey: rootVal.listKey,
              session: context.session
            });
          }

          return isFilterable !== null && isFilterable !== void 0 ? isFilterable : false;
        }

      }),
      fieldMeta: graphql.field({
        type: jsonScalar
      }),
      viewsIndex: graphql.field({
        type: graphql.nonNull(graphql.Int)
      }),
      customViewsIndex: graphql.field({
        type: graphql.Int
      }),
      createView: graphql.field({
        resolve(rootVal) {
          return {
            fieldPath: rootVal.path,
            listKey: rootVal.listKey
          };
        },

        type: graphql.nonNull(graphql.object()({
          name: 'KeystoneAdminUIFieldMetaCreateView',
          fields: {
            fieldMode: graphql.field({
              type: graphql.nonNull(graphql.enum({
                name: 'KeystoneAdminUIFieldMetaCreateViewFieldMode',
                values: graphql.enumValues(['edit', 'hidden'])
              })),

              async resolve(rootVal, args, context) {
                var _lists$rootVal$listKe3, _lists$rootVal$listKe4, _lists$rootVal$listKe5, _listConfig$ui, _listConfig$ui$create;

                if ('isAdminUIBuildProcess' in context) {
                  throw new Error('KeystoneAdminUIFieldMetaCreateView.fieldMode cannot be resolved during the build process');
                }

                if (!lists[rootVal.listKey].fields[rootVal.fieldPath].graphql.isEnabled.create) {
                  return 'hidden';
                }

                const listConfig = config.lists[rootVal.listKey];
                const sessionFunction = (_lists$rootVal$listKe3 = (_lists$rootVal$listKe4 = lists[rootVal.listKey].fields[rootVal.fieldPath].ui) === null || _lists$rootVal$listKe4 === void 0 ? void 0 : (_lists$rootVal$listKe5 = _lists$rootVal$listKe4.createView) === null || _lists$rootVal$listKe5 === void 0 ? void 0 : _lists$rootVal$listKe5.fieldMode) !== null && _lists$rootVal$listKe3 !== void 0 ? _lists$rootVal$listKe3 : (_listConfig$ui = listConfig.ui) === null || _listConfig$ui === void 0 ? void 0 : (_listConfig$ui$create = _listConfig$ui.createView) === null || _listConfig$ui$create === void 0 ? void 0 : _listConfig$ui$create.defaultFieldMode;
                return runMaybeFunction(sessionFunction, 'edit', {
                  session: context.session,
                  context
                });
              }

            })
          }
        }))
      }),
      listView: graphql.field({
        resolve(rootVal) {
          return {
            fieldPath: rootVal.path,
            listKey: rootVal.listKey
          };
        },

        type: graphql.nonNull(graphql.object()({
          name: 'KeystoneAdminUIFieldMetaListView',
          fields: {
            fieldMode: graphql.field({
              type: graphql.nonNull(graphql.enum({
                name: 'KeystoneAdminUIFieldMetaListViewFieldMode',
                values: graphql.enumValues(['read', 'hidden'])
              })),

              async resolve(rootVal, args, context) {
                var _lists$rootVal$listKe6, _lists$rootVal$listKe7, _lists$rootVal$listKe8, _listConfig$ui2, _listConfig$ui2$listV;

                if ('isAdminUIBuildProcess' in context) {
                  throw new Error('KeystoneAdminUIFieldMetaListView.fieldMode cannot be resolved during the build process');
                }

                if (!lists[rootVal.listKey].fields[rootVal.fieldPath].graphql.isEnabled.read) {
                  return 'hidden';
                }

                const listConfig = config.lists[rootVal.listKey];
                const sessionFunction = (_lists$rootVal$listKe6 = (_lists$rootVal$listKe7 = lists[rootVal.listKey].fields[rootVal.fieldPath].ui) === null || _lists$rootVal$listKe7 === void 0 ? void 0 : (_lists$rootVal$listKe8 = _lists$rootVal$listKe7.listView) === null || _lists$rootVal$listKe8 === void 0 ? void 0 : _lists$rootVal$listKe8.fieldMode) !== null && _lists$rootVal$listKe6 !== void 0 ? _lists$rootVal$listKe6 : (_listConfig$ui2 = listConfig.ui) === null || _listConfig$ui2 === void 0 ? void 0 : (_listConfig$ui2$listV = _listConfig$ui2.listView) === null || _listConfig$ui2$listV === void 0 ? void 0 : _listConfig$ui2$listV.defaultFieldMode;
                return runMaybeFunction(sessionFunction, 'read', {
                  session: context.session,
                  context
                });
              }

            })
          }
        }))
      }),
      itemView: graphql.field({
        args: {
          id: graphql.arg({
            type: graphql.ID
          })
        },

        resolve(rootVal, args) {
          var _args$id;

          return {
            fieldPath: rootVal.path,
            listKey: rootVal.listKey,
            itemId: (_args$id = args.id) !== null && _args$id !== void 0 ? _args$id : null
          };
        },

        type: graphql.object()({
          name: 'KeystoneAdminUIFieldMetaItemView',
          fields: {
            fieldMode: graphql.field({
              type: graphql.enum({
                name: 'KeystoneAdminUIFieldMetaItemViewFieldMode',
                values: graphql.enumValues(['edit', 'read', 'hidden'])
              }),

              resolve(rootVal, args, context) {
                var _ref3, _lists$rootVal$listKe9, _lists$rootVal$listKe10, _lists$rootVal$listKe11, _listConfig$ui3, _listConfig$ui3$itemV;

                if ('isAdminUIBuildProcess' in context && rootVal.itemId !== null) {
                  throw new Error('KeystoneAdminUIFieldMetaItemView.fieldMode cannot be resolved during the build process if an id is provided');
                }

                if (!lists[rootVal.listKey].fields[rootVal.fieldPath].graphql.isEnabled.read) {
                  return 'hidden';
                } else if (!lists[rootVal.listKey].fields[rootVal.fieldPath].graphql.isEnabled.update) {
                  return 'read';
                }

                const listConfig = config.lists[rootVal.listKey];
                const sessionFunction = (_ref3 = (_lists$rootVal$listKe9 = (_lists$rootVal$listKe10 = lists[rootVal.listKey].fields[rootVal.fieldPath].ui) === null || _lists$rootVal$listKe10 === void 0 ? void 0 : (_lists$rootVal$listKe11 = _lists$rootVal$listKe10.itemView) === null || _lists$rootVal$listKe11 === void 0 ? void 0 : _lists$rootVal$listKe11.fieldMode) !== null && _lists$rootVal$listKe9 !== void 0 ? _lists$rootVal$listKe9 : (_listConfig$ui3 = listConfig.ui) === null || _listConfig$ui3 === void 0 ? void 0 : (_listConfig$ui3$itemV = _listConfig$ui3.itemView) === null || _listConfig$ui3$itemV === void 0 ? void 0 : _listConfig$ui3$itemV.defaultFieldMode) !== null && _ref3 !== void 0 ? _ref3 : 'edit';

                if (typeof sessionFunction === 'string') {
                  return sessionFunction;
                }

                if (rootVal.itemId === null) {
                  return null;
                }
                // to a variable and then returned

                let ret = fetchItemForItemViewFieldMode(context)(rootVal.listKey, rootVal.itemId).then(item => {
                  if (item === null) {
                    return 'hidden';
                  }

                  return runMaybeFunction(sessionFunction, 'edit', {
                    session: context.session,
                    context,
                    item
                  });
                });
                return ret;
              }

            })
          }
        })
      }),
      search: graphql.field({
        type: QueryMode
      })
    }
  });
  const KeystoneAdminUISort = graphql.object()({
    name: 'KeystoneAdminUISort',
    fields: {
      field: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      direction: graphql.field({
        type: graphql.nonNull(graphql.enum({
          name: 'KeystoneAdminUISortDirection',
          values: graphql.enumValues(['ASC', 'DESC'])
        }))
      })
    }
  });
  const KeystoneAdminUIListMeta = graphql.object()({
    name: 'KeystoneAdminUIListMeta',
    fields: {
      key: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      itemQueryName: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      listQueryName: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      hideCreate: graphql.field({
        type: graphql.nonNull(graphql.Boolean),

        resolve(rootVal, args, context) {
          var _listConfig$ui4;

          if ('isAdminUIBuildProcess' in context) {
            throw new Error('KeystoneAdminUIListMeta.hideCreate cannot be resolved during the build process');
          }

          const listConfig = config.lists[rootVal.key];
          return runMaybeFunction((_listConfig$ui4 = listConfig.ui) === null || _listConfig$ui4 === void 0 ? void 0 : _listConfig$ui4.hideCreate, false, {
            session: context.session,
            context
          });
        }

      }),
      hideDelete: graphql.field({
        type: graphql.nonNull(graphql.Boolean),

        resolve(rootVal, args, context) {
          var _listConfig$ui5;

          if ('isAdminUIBuildProcess' in context) {
            throw new Error('KeystoneAdminUIListMeta.hideDelete cannot be resolved during the build process');
          }

          const listConfig = config.lists[rootVal.key];
          return runMaybeFunction((_listConfig$ui5 = listConfig.ui) === null || _listConfig$ui5 === void 0 ? void 0 : _listConfig$ui5.hideDelete, false, {
            session: context.session,
            context
          });
        }

      }),
      path: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      label: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      singular: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      plural: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      description: graphql.field({
        type: graphql.String
      }),
      initialColumns: graphql.field({
        type: graphql.nonNull(graphql.list(graphql.nonNull(graphql.String)))
      }),
      pageSize: graphql.field({
        type: graphql.nonNull(graphql.Int)
      }),
      labelField: graphql.field({
        type: graphql.nonNull(graphql.String)
      }),
      fields: graphql.field({
        type: graphql.nonNull(graphql.list(graphql.nonNull(KeystoneAdminUIFieldMeta)))
      }),
      initialSort: graphql.field({
        type: KeystoneAdminUISort
      }),
      isHidden: graphql.field({
        type: graphql.nonNull(graphql.Boolean),

        resolve(rootVal, args, context) {
          var _listConfig$ui6;

          if ('isAdminUIBuildProcess' in context) {
            throw new Error('KeystoneAdminUIListMeta.isHidden cannot be resolved during the build process');
          }

          const listConfig = config.lists[rootVal.key];
          return runMaybeFunction((_listConfig$ui6 = listConfig.ui) === null || _listConfig$ui6 === void 0 ? void 0 : _listConfig$ui6.isHidden, false, {
            session: context.session,
            context
          });
        }

      })
    }
  });
  const adminMeta = graphql.object()({
    name: 'KeystoneAdminMeta',
    fields: {
      enableSignout: graphql.field({
        type: graphql.nonNull(graphql.Boolean)
      }),
      enableSessionItem: graphql.field({
        type: graphql.nonNull(graphql.Boolean)
      }),
      lists: graphql.field({
        type: graphql.nonNull(graphql.list(graphql.nonNull(KeystoneAdminUIListMeta)))
      }),
      list: graphql.field({
        type: KeystoneAdminUIListMeta,
        args: {
          key: graphql.arg({
            type: graphql.nonNull(graphql.String)
          })
        },

        resolve(rootVal, _ref4) {
          let {
            key
          } = _ref4;
          return rootVal.listsByKey[key];
        }

      })
    }
  });
  const KeystoneMeta = graphql.nonNull(graphql.object()({
    name: 'KeystoneMeta',
    fields: {
      adminMeta: graphql.field({
        type: graphql.nonNull(adminMeta),

        resolve(rootVal, args, context) {
          if ('isAdminUIBuildProcess' in context || isAccessAllowed === undefined) {
            return adminMetaRoot;
          }

          return Promise.resolve(isAccessAllowed(context)).then(isAllowed => {
            if (isAllowed) {
              return adminMetaRoot;
            } // TODO: ughhhhhh, we really need to talk about errors.
            // mostly unrelated to above: error or return null here(+ make field nullable)?s


            throw new Error('Access denied');
          });
        }

      })
    }
  }));
  return {
    keystone: graphql.field({
      type: KeystoneMeta,

      resolve() {
        return {};
      }

    })
  };
}

function runMaybeFunction(sessionFunction, defaultValue, args) {
  if (typeof sessionFunction === 'function') {
    return sessionFunction(args);
  }

  if (typeof sessionFunction === 'undefined') {
    return defaultValue;
  }

  return sessionFunction;
}

const fetchItemForItemViewFieldMode = extendContext(context => {
  const lists = new Map();
  return (listKey, id) => {
    if (!lists.has(listKey)) {
      lists.set(listKey, new Map());
    }

    const items = lists.get(listKey);

    if (items.has(id)) {
      return items.get(id);
    }

    let promise = context.db[listKey].findOne({
      where: {
        id
      }
    });
    items.set(id, promise);
    return promise;
  };
});

function extendContext(cb) {
  const cache = new WeakMap();
  return context => {
    if (cache.has(context)) {
      return cache.get(context);
    }

    const result = cb(context);
    cache.set(context, result);
    return result;
  };
}

const missingItem = (operation, uniqueWhere) => accessDeniedError(`You cannot perform the '${operation}' operation on the item '${JSON.stringify(uniqueWhere)}'. It may not exist.`);

async function getFilteredItem(list, context, uniqueWhere, accessFilters, operation) {
  if (accessFilters === false) {
    // Early exit if they want to exclude everything
    throw accessDeniedError(`You cannot perform the '${operation}' operation on the list '${list.listKey}'.`);
  } // Merge the filter access control and try to get the item.


  let where = mapUniqueWhereToWhere(uniqueWhere);

  if (typeof accessFilters === 'object') {
    where = {
      AND: [where, await resolveWhereInput(accessFilters, list, context)]
    };
  }

  const item = await runWithPrisma(context, list, model => model.findFirst({
    where
  }));

  if (item === null) {
    throw missingItem(operation, uniqueWhere);
  }

  return item;
}

async function checkUniqueItemExists(uniqueInput, foreignList, context, operation) {
  // Validate and resolve the input filter
  const uniqueWhere = await resolveUniqueWhereInput(uniqueInput, foreignList.fields, context); // Check whether the item exists (from this users POV).

  try {
    const item = await context.db[foreignList.listKey].findOne({
      where: uniqueInput
    });

    if (item === null) {
      throw missingItem(operation, uniqueWhere);
    }
  } catch (err) {
    throw missingItem(operation, uniqueWhere);
  }

  return uniqueWhere;
}
async function getAccessControlledItemForDelete(list, context, uniqueWhere, accessFilters) {
  const operation = 'delete'; // Apply the filter access control. Will throw an accessDeniedError if the item isn't found.

  const item = await getFilteredItem(list, context, uniqueWhere, accessFilters, operation); // Apply item level access control

  const access = list.access.item[operation];
  const args = {
    operation,
    session: context.session,
    listKey: list.listKey,
    context,
    item
  }; // List level 'item' access control

  let result;

  try {
    result = await access(args);
  } catch (error) {
    throw extensionError('Access control', [{
      error,
      tag: `${args.listKey}.access.item.${args.operation}`
    }]);
  }

  const resultType = typeof result; // It's important that we don't cast objects to truthy values, as there's a strong chance that the user
  // has accidentally tried to return a filter.

  if (resultType !== 'boolean') {
    throw accessReturnError([{
      tag: `${args.listKey}.access.item.${args.operation}`,
      returned: resultType
    }]);
  }

  if (!result) {
    throw accessDeniedError(`You cannot perform the '${operation}' operation on the item '${JSON.stringify(uniqueWhere)}'. It may not exist.`);
  } // No field level access control for delete


  return item;
}
async function getAccessControlledItemForUpdate(list, context, uniqueWhere, accessFilters, inputData) {
  const operation = 'update'; // Apply the filter access control. Will throw an accessDeniedError if the item isn't found.

  const item = await getFilteredItem(list, context, uniqueWhere, accessFilters, operation); // Apply item level access control

  const access = list.access.item[operation];
  const args = {
    operation,
    session: context.session,
    listKey: list.listKey,
    context,
    item,
    inputData
  }; // List level 'item' access control

  let result;

  try {
    result = await access(args);
  } catch (error) {
    throw extensionError('Access control', [{
      error,
      tag: `${args.listKey}.access.item.${args.operation}`
    }]);
  }

  const resultType = typeof result; // It's important that we don't cast objects to truthy values, as there's a strong chance that the user
  // has accidentally tried to return a filter.

  if (resultType !== 'boolean') {
    throw accessReturnError([{
      tag: `${args.listKey}.access.item.${args.operation}`,
      returned: resultType
    }]);
  }

  if (!result) {
    throw accessDeniedError(`You cannot perform the '${operation}' operation on the item '${JSON.stringify(uniqueWhere)}'. It may not exist.`);
  } // Field level 'item' access control


  const nonBooleans = [];
  const fieldsDenied = [];
  const accessErrors = [];
  await Promise.all(Object.keys(inputData).map(async fieldKey => {
    let result;

    try {
      result = typeof list.fields[fieldKey].access[operation] === 'function' ? await list.fields[fieldKey].access[operation](_objectSpread(_objectSpread({}, args), {}, {
        fieldKey
      })) : access;
    } catch (error) {
      accessErrors.push({
        error,
        tag: `${args.listKey}.${fieldKey}.access.${args.operation}`
      });
      return;
    }

    if (typeof result !== 'boolean') {
      nonBooleans.push({
        tag: `${args.listKey}.${fieldKey}.access.${args.operation}`,
        returned: typeof result
      });
    } else if (!result) {
      fieldsDenied.push(fieldKey);
    }
  }));

  if (accessErrors.length) {
    throw extensionError('Access control', accessErrors);
  }

  if (nonBooleans.length) {
    throw accessReturnError(nonBooleans);
  }

  if (fieldsDenied.length) {
    throw accessDeniedError(`You cannot perform the '${operation}' operation on the item '${JSON.stringify(uniqueWhere)}'. You cannot ${operation} the fields ${JSON.stringify(fieldsDenied)}.`);
  }

  return item;
}
async function applyAccessControlForCreate(list, context, inputData) {
  const operation = 'create'; // Apply item level access control

  const access = list.access.item[operation];
  const args = {
    operation,
    session: context.session,
    listKey: list.listKey,
    context,
    inputData
  }; // List level 'item' access control

  let result;

  try {
    result = await access(args);
  } catch (error) {
    throw extensionError('Access control', [{
      error,
      tag: `${args.listKey}.access.item.${args.operation}`
    }]);
  }

  const resultType = typeof result; // It's important that we don't cast objects to truthy values, as there's a strong chance that the user
  // has accidentally tried to return a filter.

  if (resultType !== 'boolean') {
    throw accessReturnError([{
      tag: `${args.listKey}.access.item.${args.operation}`,
      returned: resultType
    }]);
  }

  if (!result) {
    throw accessDeniedError(`You cannot perform the '${operation}' operation on the item '${JSON.stringify(inputData)}'.`);
  } // Field level 'item' access control


  const nonBooleans = [];
  const fieldsDenied = [];
  const accessErrors = [];
  await Promise.all(Object.keys(inputData).map(async fieldKey => {
    let result;

    try {
      result = typeof list.fields[fieldKey].access[operation] === 'function' ? await list.fields[fieldKey].access[operation](_objectSpread(_objectSpread({}, args), {}, {
        fieldKey
      })) : access;
    } catch (error) {
      accessErrors.push({
        error,
        tag: `${args.listKey}.${fieldKey}.access.${args.operation}`
      });
      return;
    }

    if (typeof result !== 'boolean') {
      nonBooleans.push({
        tag: `${args.listKey}.${fieldKey}.access.${args.operation}`,
        returned: typeof result
      });
    } else if (!result) {
      fieldsDenied.push(fieldKey);
    }
  }));

  if (accessErrors.length) {
    throw extensionError('Access control', accessErrors);
  }

  if (nonBooleans.length) {
    throw accessReturnError(nonBooleans);
  }

  if (fieldsDenied.length) {
    throw accessDeniedError(`You cannot perform the '${operation}' operation on the item '${JSON.stringify(inputData)}'. You cannot ${operation} the fields ${JSON.stringify(fieldsDenied)}.`);
  }
}

class RelationshipErrors extends Error {
  constructor(errors) {
    super('Multiple relationship errors');

    _defineProperty(this, "errors", void 0);

    this.errors = errors;
  }

}

function getResolvedUniqueWheres(uniqueInputs, context, foreignList, operation) {
  return uniqueInputs.map(uniqueInput => checkUniqueItemExists(uniqueInput, foreignList, context, operation));
}

function resolveRelateToManyForCreateInput(nestedMutationState, context, foreignList, tag) {
  return async value => {
    if (!Array.isArray(value.connect) && !Array.isArray(value.create)) {
      throw userInputError(`You must provide "connect" or "create" in to-many relationship inputs for "create" operations.`);
    } // Perform queries for the connections


    const connects = Promise.allSettled(getResolvedUniqueWheres(value.connect || [], context, foreignList, 'connect')); // Perform nested mutations for the creations

    const creates = Promise.allSettled((value.create || []).map(x => nestedMutationState.create(x, foreignList)));
    const [connectResult, createResult] = await Promise.all([connects, creates]); // Collect all the errors

    const errors = [...connectResult, ...createResult].filter(isRejected);

    if (errors.length) {
      throw new RelationshipErrors(errors.map(x => ({
        error: x.reason,
        tag
      })));
    }

    const result = {
      connect: [...connectResult, ...createResult].filter(isFulfilled).map(x => x.value)
    }; // Perform queries for the connections

    return result;
  };
}
function resolveRelateToManyForUpdateInput(nestedMutationState, context, foreignList, tag) {
  return async value => {
    if (!Array.isArray(value.connect) && !Array.isArray(value.create) && !Array.isArray(value.disconnect) && !Array.isArray(value.set)) {
      throw userInputError(`You must provide at least one of "set", "connect", "create" or "disconnect" in to-many relationship inputs for "update" operations.`);
    }

    if (value.set && value.disconnect) {
      throw userInputError(`The "set" and "disconnect" fields cannot both be provided to to-many relationship inputs for "update" operations.`);
    } // Perform queries for the connections


    const connects = Promise.allSettled(getResolvedUniqueWheres(value.connect || [], context, foreignList, 'connect'));
    const disconnects = Promise.allSettled(getResolvedUniqueWheres(value.disconnect || [], context, foreignList, 'disconnect'));
    const sets = Promise.allSettled(getResolvedUniqueWheres(value.set || [], context, foreignList, 'set')); // Perform nested mutations for the creations

    const creates = Promise.allSettled((value.create || []).map(x => nestedMutationState.create(x, foreignList)));
    const [connectResult, createResult, disconnectResult, setResult] = await Promise.all([connects, creates, disconnects, sets]); // Collect all the errors

    const errors = [...connectResult, ...createResult, ...disconnectResult, ...setResult].filter(isRejected);

    if (errors.length) {
      throw new RelationshipErrors(errors.map(x => ({
        error: x.reason,
        tag
      })));
    }

    return {
      // unlike all the other operations, an empty array isn't a no-op for set
      set: value.set ? setResult.filter(isFulfilled).map(x => x.value) : undefined,
      disconnect: disconnectResult.filter(isFulfilled).map(x => x.value),
      connect: [...connectResult, ...createResult].filter(isFulfilled).map(x => x.value)
    };
  };
}

async function handleCreateAndUpdate(value, nestedMutationState, context, foreignList) {
  if (value.connect) {
    return {
      connect: await checkUniqueItemExists(value.connect, foreignList, context, 'connect')
    };
  } else if (value.create) {
    const {
      id
    } = await nestedMutationState.create(value.create, foreignList);
    return {
      connect: {
        id
      }
    };
  }
}

function resolveRelateToOneForCreateInput(nestedMutationState, context, foreignList) {
  return async value => {
    const numOfKeys = Object.keys(value).length;

    if (numOfKeys !== 1) {
      throw userInputError(`You must provide "connect" or "create" in to-one relationship inputs for "create" operations.`);
    }

    return handleCreateAndUpdate(value, nestedMutationState, context, foreignList);
  };
}
function resolveRelateToOneForUpdateInput(nestedMutationState, context, foreignList) {
  return async value => {
    if (Object.keys(value).length !== 1) {
      throw userInputError(`You must provide one of "connect", "create" or "disconnect" in to-one relationship inputs for "update" operations.`);
    }

    if (value.connect || value.create) {
      return handleCreateAndUpdate(value, nestedMutationState, context, foreignList);
    } else if (value.disconnect) {
      return {
        disconnect: true
      };
    }
  };
}

async function runSideEffectOnlyHook(list, hookName, args) {
  // Runs the before/after operation hooks
  let shouldRunFieldLevelHook;

  if (args.operation === 'delete') {
    // Always run field hooks for delete operations
    shouldRunFieldLevelHook = () => true;
  } else {
    // Only run field hooks on if the field was specified in the
    // original input for create and update operations.
    const inputDataKeys = new Set(Object.keys(args.inputData));

    shouldRunFieldLevelHook = fieldKey => inputDataKeys.has(fieldKey);
  } // Field hooks


  const fieldsErrors = [];
  await Promise.all(Object.entries(list.fields).map(async _ref => {
    let [fieldKey, field] = _ref;

    if (shouldRunFieldLevelHook(fieldKey)) {
      try {
        var _field$hooks$hookName, _field$hooks;

        await ((_field$hooks$hookName = (_field$hooks = field.hooks)[hookName]) === null || _field$hooks$hookName === void 0 ? void 0 : _field$hooks$hookName.call(_field$hooks, _objectSpread({
          fieldKey
        }, args)));
      } catch (error) {
        fieldsErrors.push({
          error,
          tag: `${list.listKey}.${fieldKey}.hooks.${hookName}`
        });
      }
    }
  }));

  if (fieldsErrors.length) {
    throw extensionError(hookName, fieldsErrors);
  } // List hooks


  try {
    var _list$hooks$hookName, _list$hooks;

    await ((_list$hooks$hookName = (_list$hooks = list.hooks)[hookName]) === null || _list$hooks$hookName === void 0 ? void 0 : _list$hooks$hookName.call(_list$hooks, args));
  } catch (error) {
    throw extensionError(hookName, [{
      error,
      tag: `${list.listKey}.hooks.${hookName}`
    }]);
  }
}

async function validateUpdateCreate(_ref) {
  let {
    list,
    hookArgs
  } = _ref;
  const messages = [];
  const fieldsErrors = []; // Field validation hooks

  await Promise.all(Object.entries(list.fields).map(async _ref2 => {
    let [fieldKey, field] = _ref2;

    const addValidationError = msg => messages.push(`${list.listKey}.${fieldKey}: ${msg}`);

    try {
      var _field$hooks$validate, _field$hooks;

      await ((_field$hooks$validate = (_field$hooks = field.hooks).validateInput) === null || _field$hooks$validate === void 0 ? void 0 : _field$hooks$validate.call(_field$hooks, _objectSpread(_objectSpread({}, hookArgs), {}, {
        addValidationError,
        fieldKey
      })));
    } catch (error) {
      fieldsErrors.push({
        error,
        tag: `${list.listKey}.${fieldKey}.hooks.validateInput`
      });
    }
  }));

  if (fieldsErrors.length) {
    throw extensionError('validateInput', fieldsErrors);
  } // List validation hooks


  const addValidationError = msg => messages.push(`${list.listKey}: ${msg}`);

  try {
    var _list$hooks$validateI, _list$hooks;

    await ((_list$hooks$validateI = (_list$hooks = list.hooks).validateInput) === null || _list$hooks$validateI === void 0 ? void 0 : _list$hooks$validateI.call(_list$hooks, _objectSpread(_objectSpread({}, hookArgs), {}, {
      addValidationError
    })));
  } catch (error) {
    throw extensionError('validateInput', [{
      error,
      tag: `${list.listKey}.hooks.validateInput`
    }]);
  }

  if (messages.length) {
    throw validationFailureError(messages);
  }
}
async function validateDelete(_ref3) {
  let {
    list,
    hookArgs
  } = _ref3;
  const messages = [];
  const fieldsErrors = []; // Field validation

  await Promise.all(Object.entries(list.fields).map(async _ref4 => {
    let [fieldKey, field] = _ref4;

    const addValidationError = msg => messages.push(`${list.listKey}.${fieldKey}: ${msg}`);

    try {
      var _field$hooks$validate2, _field$hooks2;

      await ((_field$hooks$validate2 = (_field$hooks2 = field.hooks).validateDelete) === null || _field$hooks$validate2 === void 0 ? void 0 : _field$hooks$validate2.call(_field$hooks2, _objectSpread(_objectSpread({}, hookArgs), {}, {
        addValidationError,
        fieldKey
      })));
    } catch (error) {
      fieldsErrors.push({
        error,
        tag: `${list.listKey}.${fieldKey}.hooks.validateDelete`
      });
    }
  }));

  if (fieldsErrors.length) {
    throw extensionError('validateDelete', fieldsErrors);
  } // List validation


  const addValidationError = msg => messages.push(`${list.listKey}: ${msg}`);

  try {
    var _list$hooks$validateD, _list$hooks2;

    await ((_list$hooks$validateD = (_list$hooks2 = list.hooks).validateDelete) === null || _list$hooks$validateD === void 0 ? void 0 : _list$hooks$validateD.call(_list$hooks2, _objectSpread(_objectSpread({}, hookArgs), {}, {
      addValidationError
    })));
  } catch (error) {
    throw extensionError('validateDelete', [{
      error,
      tag: `${list.listKey}.hooks.validateDelete`
    }]);
  }

  if (messages.length) {
    throw validationFailureError(messages);
  }
}

async function createSingle(_ref, list, context, operationAccess) {
  let {
    data: rawData
  } = _ref;

  // Operation level access control
  if (!operationAccess) {
    throw accessDeniedError(`You cannot perform the 'create' operation on the list '${list.listKey}'.`);
  } //  Item access control. Will throw an accessDeniedError if not allowed.


  await applyAccessControlForCreate(list, context, rawData);
  const {
    afterOperation,
    data
  } = await resolveInputForCreateOrUpdate(list, context, rawData, undefined);
  const writeLimit = getWriteLimit(context);
  const item = await writeLimit(() => runWithPrisma(context, list, model => model.create({
    data
  })));
  return {
    item,
    afterOperation
  };
}

var _afterOperations = /*#__PURE__*/new WeakMap();

var _context = /*#__PURE__*/new WeakMap();

class NestedMutationState {
  constructor(context) {
    _classPrivateFieldInitSpec(this, _afterOperations, {
      writable: true,
      value: []
    });

    _classPrivateFieldInitSpec(this, _context, {
      writable: true,
      value: void 0
    });

    _classPrivateFieldSet(this, _context, context);
  }

  async create(data, list) {
    const context = _classPrivateFieldGet(this, _context); // Check operation permission to pass into single operation


    const operationAccess = await getOperationAccess(list, context, 'create');
    const {
      item,
      afterOperation
    } = await createSingle({
      data
    }, list, context, operationAccess);

    _classPrivateFieldGet(this, _afterOperations).push(() => afterOperation(item));

    return {
      id: item.id
    };
  }

  async afterOperation() {
    await promiseAllRejectWithAllErrors(_classPrivateFieldGet(this, _afterOperations).map(async x => x()));
  }

}
async function createOne(createInput, list, context) {
  // Check operation permission to pass into single operation
  const operationAccess = await getOperationAccess(list, context, 'create');
  const {
    item,
    afterOperation
  } = await createSingle(createInput, list, context, operationAccess);
  await afterOperation(item);
  return item;
}
async function createMany(createInputs, list, context) {
  // Check operation permission to pass into single operation
  const operationAccess = await getOperationAccess(list, context, 'create');
  return createInputs.data.map(async data => {
    const {
      item,
      afterOperation
    } = await createSingle({
      data
    }, list, context, operationAccess);
    await afterOperation(item);
    return item;
  });
}

async function updateSingle(updateInput, list, context, accessFilters, operationAccess) {
  // Operation level access control
  if (!operationAccess) {
    throw accessDeniedError(`You cannot perform the 'update' operation on the list '${list.listKey}'.`);
  }

  const {
    where: uniqueInput,
    data: rawData
  } = updateInput; // Validate and resolve the input filter

  const uniqueWhere = await resolveUniqueWhereInput(uniqueInput, list.fields, context); // Check filter access

  const fieldKey = Object.keys(uniqueWhere)[0];
  await checkFilterOrderAccess([{
    fieldKey,
    list
  }], context, 'filter'); // Filter and Item access control. Will throw an accessDeniedError if not allowed.

  const item = await getAccessControlledItemForUpdate(list, context, uniqueWhere, accessFilters, rawData);
  const {
    afterOperation,
    data
  } = await resolveInputForCreateOrUpdate(list, context, rawData, item);
  const writeLimit = getWriteLimit(context);
  const updatedItem = await writeLimit(() => runWithPrisma(context, list, model => model.update({
    where: {
      id: item.id
    },
    data
  })));
  await afterOperation(updatedItem);
  return updatedItem;
}

async function updateOne(updateInput, list, context) {
  // Check operation permission to pass into single operation
  const operationAccess = await getOperationAccess(list, context, 'update'); // Get list-level access control filters

  const accessFilters = await getAccessFilters(list, context, 'update');
  return updateSingle(updateInput, list, context, accessFilters, operationAccess);
}
async function updateMany(_ref2, list, context) {
  let {
    data
  } = _ref2;
  // Check operation permission to pass into single operation
  const operationAccess = await getOperationAccess(list, context, 'update'); // Get list-level access control filters

  const accessFilters = await getAccessFilters(list, context, 'update');
  return data.map(async updateInput => updateSingle(updateInput, list, context, accessFilters, operationAccess));
}

async function getResolvedData(list, hookArgs, nestedMutationState) {
  const {
    context,
    operation
  } = hookArgs; // Start with the original input

  let resolvedData = hookArgs.inputData; // Apply non-relationship field type input resolvers

  const resolverErrors = [];
  resolvedData = Object.fromEntries(await Promise.all(Object.entries(list.fields).map(async _ref3 => {
    var _field$input, _field$input$operatio;

    let [fieldKey, field] = _ref3;
    const inputResolver = (_field$input = field.input) === null || _field$input === void 0 ? void 0 : (_field$input$operatio = _field$input[operation]) === null || _field$input$operatio === void 0 ? void 0 : _field$input$operatio.resolve;
    let input = resolvedData[fieldKey];

    if (inputResolver && field.dbField.kind !== 'relation') {
      try {
        input = await inputResolver(input, context, undefined);
      } catch (error) {
        resolverErrors.push({
          error,
          tag: `${list.listKey}.${fieldKey}`
        });
      }
    }

    return [fieldKey, input];
  })));

  if (resolverErrors.length) {
    throw resolverError(resolverErrors);
  } // Apply relationship field type input resolvers


  const relationshipErrors = [];
  resolvedData = Object.fromEntries(await Promise.all(Object.entries(list.fields).map(async _ref4 => {
    var _field$input2, _field$input2$operati;

    let [fieldKey, field] = _ref4;
    const inputResolver = (_field$input2 = field.input) === null || _field$input2 === void 0 ? void 0 : (_field$input2$operati = _field$input2[operation]) === null || _field$input2$operati === void 0 ? void 0 : _field$input2$operati.resolve;
    let input = resolvedData[fieldKey];

    if (inputResolver && field.dbField.kind === 'relation') {
      const tag = `${list.listKey}.${fieldKey}`;

      try {
        input = await inputResolver(input, context, // This third argument only applies to relationship fields
        (() => {
          if (input === undefined) {
            // No-op: This is what we want
            return () => undefined;
          }

          if (input === null) {
            // No-op: Should this be UserInputError?
            return () => undefined;
          }

          const foreignList = list.lists[field.dbField.list];
          let resolver;

          if (field.dbField.mode === 'many') {
            if (operation === 'create') {
              resolver = resolveRelateToManyForCreateInput;
            } else {
              resolver = resolveRelateToManyForUpdateInput;
            }
          } else {
            if (operation === 'create') {
              resolver = resolveRelateToOneForCreateInput;
            } else {
              resolver = resolveRelateToOneForUpdateInput;
            }
          }

          return resolver(nestedMutationState, context, foreignList, tag);
        })());
      } catch (error) {
        if (error instanceof RelationshipErrors) {
          relationshipErrors.push(...error.errors);
        } else {
          relationshipErrors.push({
            error,
            tag
          });
        }
      }
    }

    return [fieldKey, input];
  })));

  if (relationshipErrors.length) {
    throw relationshipError(relationshipErrors);
  } // Resolve input hooks


  const hookName = 'resolveInput'; // Field hooks

  const fieldsErrors = [];
  resolvedData = Object.fromEntries(await Promise.all(Object.entries(list.fields).map(async _ref5 => {
    let [fieldKey, field] = _ref5;

    if (field.hooks.resolveInput === undefined) {
      return [fieldKey, resolvedData[fieldKey]];
    } else {
      try {
        return [fieldKey, await field.hooks.resolveInput(_objectSpread(_objectSpread({}, hookArgs), {}, {
          resolvedData,
          fieldKey
        }))];
      } catch (error) {
        fieldsErrors.push({
          error,
          tag: `${list.listKey}.${fieldKey}.hooks.${hookName}`
        });
        return [fieldKey, undefined];
      }
    }
  })));

  if (fieldsErrors.length) {
    throw extensionError(hookName, fieldsErrors);
  } // List hooks


  if (list.hooks.resolveInput) {
    try {
      resolvedData = await list.hooks.resolveInput(_objectSpread(_objectSpread({}, hookArgs), {}, {
        resolvedData
      }));
    } catch (error) {
      throw extensionError(hookName, [{
        error,
        tag: `${list.listKey}.hooks.${hookName}`
      }]);
    }
  }

  return resolvedData;
}

async function resolveInputForCreateOrUpdate(list, context, inputData, item) {
  const nestedMutationState = new NestedMutationState(context);
  const baseHookArgs = {
    context,
    listKey: list.listKey,
    inputData,
    resolvedData: {}
  };
  const hookArgs = item === undefined ? _objectSpread(_objectSpread({}, baseHookArgs), {}, {
    operation: 'create',
    item
  }) : _objectSpread(_objectSpread({}, baseHookArgs), {}, {
    operation: 'update',
    item
  }); // Take the original input and resolve all the fields down to what
  // will be saved into the database.

  hookArgs.resolvedData = await getResolvedData(list, hookArgs, nestedMutationState); // Apply all validation checks

  await validateUpdateCreate({
    list,
    hookArgs
  }); // Run beforeOperation hooks

  await runSideEffectOnlyHook(list, 'beforeOperation', hookArgs); // Return the full resolved input (ready for prisma level operation),
  // and the afterOperation hook to be applied

  return {
    data: flattenMultiDbFields(list.fields, hookArgs.resolvedData),
    afterOperation: async updatedItem => {
      await nestedMutationState.afterOperation();
      await runSideEffectOnlyHook(list, 'afterOperation', // at runtime this conditional is pointless
      // but TypeScript needs it because in each case, it will narrow
      // `hookArgs` based on the `operation` which will make `hookArgs.item`
      // be the right type for `originalItem` for the operation
      hookArgs.operation === 'create' ? _objectSpread(_objectSpread({}, hookArgs), {}, {
        item: updatedItem,
        originalItem: hookArgs.item
      }) : _objectSpread(_objectSpread({}, hookArgs), {}, {
        item: updatedItem,
        originalItem: hookArgs.item
      }));
    }
  };
}

function flattenMultiDbFields(fields, data) {
  return Object.fromEntries(Object.entries(data).flatMap(_ref6 => {
    let [fieldKey, value] = _ref6;
    const {
      dbField
    } = fields[fieldKey];

    if (dbField.kind === 'multi') {
      return Object.entries(value).map(_ref7 => {
        let [innerFieldKey, fieldValue] = _ref7;
        return [getDBFieldKeyForFieldOnMultiField(fieldKey, innerFieldKey), fieldValue];
      });
    }

    return [[fieldKey, value]];
  }));
}

async function deleteSingle(uniqueInput, list, context, accessFilters, operationAccess) {
  // Operation level access control
  if (!operationAccess) {
    throw accessDeniedError(`You cannot perform the 'delete' operation on the list '${list.listKey}'.`);
  } // Validate and resolve the input filter


  const uniqueWhere = await resolveUniqueWhereInput(uniqueInput, list.fields, context); // Check filter access

  const fieldKey = Object.keys(uniqueWhere)[0];
  await checkFilterOrderAccess([{
    fieldKey,
    list
  }], context, 'filter'); // Filter and Item access control. Will throw an accessDeniedError if not allowed.

  const item = await getAccessControlledItemForDelete(list, context, uniqueWhere, accessFilters);
  const hookArgs = {
    operation: 'delete',
    listKey: list.listKey,
    context,
    item,
    resolvedData: undefined,
    inputData: undefined
  }; // Apply all validation checks

  await validateDelete({
    list,
    hookArgs
  }); // Before operation

  await runSideEffectOnlyHook(list, 'beforeOperation', hookArgs);
  const writeLimit = getWriteLimit(context);
  const newItem = await writeLimit(() => runWithPrisma(context, list, model => model.delete({
    where: {
      id: item.id
    }
  })));
  await runSideEffectOnlyHook(list, 'afterOperation', _objectSpread(_objectSpread({}, hookArgs), {}, {
    item: undefined,
    originalItem: item
  }));
  return newItem;
}

async function deleteMany(uniqueInputs, list, context) {
  // Check operation permission to pass into single operation
  const operationAccess = await getOperationAccess(list, context, 'delete'); // Check filter permission to pass into single operation

  const accessFilters = await getAccessFilters(list, context, 'delete');
  return uniqueInputs.map(async uniqueInput => deleteSingle(uniqueInput, list, context, accessFilters, operationAccess));
}
async function deleteOne(uniqueInput, list, context) {
  // Check operation permission to pass into single operation
  const operationAccess = await getOperationAccess(list, context, 'delete'); // Check filter permission to pass into single operation

  const accessFilters = await getAccessFilters(list, context, 'delete');
  return deleteSingle(uniqueInput, list, context, accessFilters, operationAccess);
}

// Basically, old keystone uses Promise.allSettled and then after that maps that into promises that resolve and reject,
// whereas the new stuff is just like "here are some promises" with no guarantees about the order they will be settled in.
// That doesn't matter when they all resolve successfully because the order they resolve successfully in
// doesn't affect anything, If some reject though, the order that they reject in will be the order in the errors array
// and some of our tests rely on the order of the graphql errors array. They shouldn't, but they do.

function promisesButSettledWhenAllSettledAndInOrder(promises) {
  const resultsPromise = Promise.allSettled(promises);
  return promises.map(async (_, i) => {
    const result = (await resultsPromise)[i];
    return result.status === 'fulfilled' ? Promise.resolve(result.value) : Promise.reject(result.reason);
  });
}

function getMutationsForList(list$1) {
  const names = getGqlNames(list$1);
  const createOne$1 = field({
    type: list$1.types.output,
    args: {
      data: arg({
        type: nonNull(list$1.types.create)
      })
    },

    resolve(_rootVal, _ref, context) {
      let {
        data
      } = _ref;
      return createOne({
        data
      }, list$1, context);
    }

  });
  const createMany$1 = field({
    type: list(list$1.types.output),
    args: {
      data: arg({
        type: nonNull(list(nonNull(list$1.types.create)))
      })
    },

    async resolve(_rootVal, args, context) {
      return promisesButSettledWhenAllSettledAndInOrder(await createMany(args, list$1, context));
    }

  });
  const updateOne$1 = field({
    type: list$1.types.output,
    args: {
      where: arg({
        type: nonNull(list$1.types.uniqueWhere)
      }),
      data: arg({
        type: nonNull(list$1.types.update)
      })
    },

    resolve(_rootVal, args, context) {
      return updateOne(args, list$1, context);
    }

  });
  const updateManyInput = inputObject({
    name: names.updateManyInputName,
    fields: {
      where: arg({
        type: nonNull(list$1.types.uniqueWhere)
      }),
      data: arg({
        type: nonNull(list$1.types.update)
      })
    }
  });
  const updateMany$1 = field({
    type: list(list$1.types.output),
    args: {
      data: arg({
        type: nonNull(list(nonNull(updateManyInput)))
      })
    },

    async resolve(_rootVal, args, context) {
      return promisesButSettledWhenAllSettledAndInOrder(await updateMany(args, list$1, context));
    }

  });
  const deleteOne$1 = field({
    type: list$1.types.output,
    args: {
      where: arg({
        type: nonNull(list$1.types.uniqueWhere)
      })
    },

    resolve(rootVal, _ref2, context) {
      let {
        where
      } = _ref2;
      return deleteOne(where, list$1, context);
    }

  });
  const deleteMany$1 = field({
    type: list(list$1.types.output),
    args: {
      where: arg({
        type: nonNull(list(nonNull(list$1.types.uniqueWhere)))
      })
    },

    async resolve(rootVal, _ref3, context) {
      let {
        where
      } = _ref3;
      return promisesButSettledWhenAllSettledAndInOrder(await deleteMany(where, list$1, context));
    }

  });
  return {
    mutations: _objectSpread(_objectSpread(_objectSpread({}, list$1.graphql.isEnabled.create && {
      [names.createMutationName]: createOne$1,
      [names.createManyMutationName]: createMany$1
    }), list$1.graphql.isEnabled.update && {
      [names.updateMutationName]: updateOne$1,
      [names.updateManyMutationName]: updateMany$1
    }), list$1.graphql.isEnabled.delete && {
      [names.deleteMutationName]: deleteOne$1,
      [names.deleteManyMutationName]: deleteMany$1
    }),
    updateManyInput
  };
}

function getQueriesForList(list$1) {
  if (!list$1.graphql.isEnabled.query) return {};
  const names = getGqlNames(list$1);
  const findOne$1 = field({
    type: list$1.types.output,
    args: {
      where: arg({
        type: nonNull(list$1.types.uniqueWhere)
      })
    },

    async resolve(_rootVal, args, context) {
      return findOne(args, list$1, context);
    }

  });
  const findMany$1 = field({
    type: list(nonNull(list$1.types.output)),
    args: list$1.types.findManyArgs,

    async resolve(_rootVal, args, context, info) {
      return findMany(args, list$1, context, info);
    }

  });
  const countQuery = field({
    type: Int,
    args: {
      where: arg({
        type: nonNull(list$1.types.where),
        defaultValue: {}
      })
    },

    async resolve(_rootVal, args, context, info) {
      return count(args, list$1, context, info);
    }

  });
  return {
    [names.listQueryName]: findMany$1,
    [names.itemQueryName]: findOne$1,
    [names.listQueryCountName]: countQuery
  };
}

function getGraphQLSchema(lists, extraFields) {
  const query = object()({
    name: 'Query',
    fields: Object.assign({}, ...Object.values(lists).map(list => getQueriesForList(list)), extraFields.query)
  });
  const updateManyByList = {};
  const mutation = object()({
    name: 'Mutation',
    fields: Object.assign({}, ...Object.values(lists).map(list => {
      const {
        mutations,
        updateManyInput
      } = getMutationsForList(list);
      updateManyByList[list.listKey] = updateManyInput;
      return mutations;
    }), extraFields.mutation)
  });
  const graphQLSchema = new GraphQLSchema({
    query: query.graphQLType,
    mutation: mutation.graphQLType,
    // not about behaviour, only ordering
    types: [...collectTypes(lists, updateManyByList), mutation.graphQLType]
  });
  return graphQLSchema;
}

function collectTypes(lists, updateManyByList) {
  const collectedTypes = [];

  for (const list of Object.values(lists)) {
    const {
      isEnabled
    } = list.graphql;
    if (!isEnabled.type) continue; // adding all of these types explicitly isn't strictly necessary but we do it to create a certain order in the schema

    collectedTypes.push(list.types.output.graphQLType);

    if (isEnabled.query || isEnabled.update || isEnabled.delete) {
      collectedTypes.push(list.types.uniqueWhere.graphQLType);
    }

    if (isEnabled.query) {
      for (const field of Object.values(list.fields)) {
        if (isEnabled.query && field.graphql.isEnabled.read && field.unreferencedConcreteInterfaceImplementations) {
          // this _IS_ actually necessary since they aren't implicitly referenced by other types, unlike the types above
          collectedTypes.push(...field.unreferencedConcreteInterfaceImplementations.map(x => x.graphQLType));
        }
      }

      collectedTypes.push(list.types.where.graphQLType);
      collectedTypes.push(list.types.orderBy.graphQLType);
    }

    if (isEnabled.update) {
      collectedTypes.push(list.types.update.graphQLType);
      collectedTypes.push(updateManyByList[list.listKey].graphQLType);
    }

    if (isEnabled.create) {
      collectedTypes.push(list.types.create.graphQLType);
    }
  } // this is not necessary, just about ordering


  collectedTypes.push(JSON$1.graphQLType);
  return collectedTypes;
}

function createGraphQLSchema(config, lists, adminMeta) {
  // Start with the core keystone graphQL schema
  let graphQLSchema = getGraphQLSchema(lists, {
    mutation: config.session ? {
      endSession: field({
        type: nonNull(Boolean),

        async resolve(rootVal, args, context) {
          if (context.endSession) {
            await context.endSession();
          }

          return true;
        }

      })
    } : {},
    query: getAdminMetaSchema({
      adminMeta,
      config,
      lists
    })
  }); // Merge in the user defined graphQL API

  if (config.extendGraphqlSchema) {
    graphQLSchema = config.extendGraphqlSchema(graphQLSchema);
  }

  return graphQLSchema;
}

function getRootTypeName(type) {
  if (type instanceof GraphQLNonNull) {
    return getRootTypeName(type.ofType);
  }

  if (type instanceof GraphQLList) {
    return getRootTypeName(type.ofType);
  }

  return type.name;
}

function executeGraphQLFieldWithSelection(schema, operation, fieldName) {
  const rootType = operation === 'mutation' ? schema.getMutationType() : schema.getQueryType();
  const field = rootType.getFields()[fieldName];

  if (field === undefined) {
    return () => {
      // This will be triggered if the field is missing due to `omit` configuration.
      // The GraphQL equivalent would be a bad user input error.
      throw new Error(`This ${operation} is not supported by the GraphQL schema: ${fieldName}()`);
    };
  }

  const {
    argumentNodes,
    variableDefinitions
  } = getVariablesForGraphQLField(field);
  const rootName = getRootTypeName(field.type);
  return async (args, query, context) => {
    var _result$errors;

    const selectionSet = parse(`fragment x on ${rootName} {${query}}`).definitions[0].selectionSet;
    const document = {
      kind: 'Document',
      definitions: [{
        kind: 'OperationDefinition',
        operation,
        selectionSet: {
          kind: 'SelectionSet',
          selections: [{
            kind: 'Field',
            name: {
              kind: 'Name',
              value: field.name
            },
            arguments: argumentNodes,
            selectionSet: selectionSet
          }]
        },
        variableDefinitions
      }]
    };
    const validationErrors = validate(schema, document);

    if (validationErrors.length > 0) {
      throw validationErrors[0];
    }

    const result = await execute({
      schema,
      document,
      contextValue: context,
      variableValues: Object.fromEntries( // GraphQL for some reason decides to make undefined values in args
      // skip defaulting for some reason
      // this ofc doesn't technically fully fix it (bc nested things)
      // but for the cases where we care, it does
      Object.entries(args).filter(_ref => {
        let [, val] = _ref;
        return val !== undefined;
      })),
      rootValue: {}
    });

    if ((_result$errors = result.errors) !== null && _result$errors !== void 0 && _result$errors.length) {
      throw result.errors[0];
    }

    return result.data[field.name];
  };
}

const _excluded = ["query"];
// (i mean it's not really any more incorrect than TS is generally is but let's ignore that)

const objectEntriesButUsingKeyof = Object.entries;
function getDbAPIFactory(gqlNames, schema) {
  const f = (operation, fieldName) => {
    const rootType = operation === 'mutation' ? schema.getMutationType() : schema.getQueryType();
    const field = rootType.getFields()[fieldName];

    if (field === undefined) {
      return () => {
        // This will be triggered if the field is missing due to `omit` configuration.
        // The GraphQL equivalent would be a bad user input error.
        throw new Error(`This ${operation} is not supported by the GraphQL schema: ${fieldName}()`);
      };
    }

    return executeGraphQLFieldToRootVal(field);
  };

  const api = {
    findOne: f('query', gqlNames.itemQueryName),
    findMany: f('query', gqlNames.listQueryName),
    count: f('query', gqlNames.listQueryCountName),
    createOne: f('mutation', gqlNames.createMutationName),
    createMany: f('mutation', gqlNames.createManyMutationName),
    updateOne: f('mutation', gqlNames.updateMutationName),
    updateMany: f('mutation', gqlNames.updateManyMutationName),
    deleteOne: f('mutation', gqlNames.deleteMutationName),
    deleteMany: f('mutation', gqlNames.deleteManyMutationName)
  };
  return context => Object.fromEntries(objectEntriesButUsingKeyof(api).map(_ref => {
    let [key, impl] = _ref;
    return [key, args => impl(args, context)];
  }));
}
function itemAPIForList(listKey, context) {
  const f = (operation, field) => {
    const exec = executeGraphQLFieldWithSelection(context.graphql.schema, operation, field);
    return function () {
      let _ref2 = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};

      let {
        query
      } = _ref2,
          args = _objectWithoutProperties(_ref2, _excluded);

      const returnFields = query !== null && query !== void 0 ? query : 'id';
      return exec(args, returnFields, context);
    };
  };

  const gqlNames = context.gqlNames(listKey);
  return {
    findOne: f('query', gqlNames.itemQueryName),
    findMany: f('query', gqlNames.listQueryName),

    async count() {
      let {
        where = {}
      } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
      const {
        listQueryCountName,
        whereInputName
      } = context.gqlNames(listKey);
      const query = `query ($where: ${whereInputName}!) { count: ${listQueryCountName}(where: $where)  }`;
      const response = await context.graphql.run({
        query,
        variables: {
          where
        }
      });
      return response.count;
    },

    createOne: f('mutation', gqlNames.createMutationName),
    createMany: f('mutation', gqlNames.createManyMutationName),
    updateOne: f('mutation', gqlNames.updateMutationName),
    updateMany: f('mutation', gqlNames.updateManyMutationName),
    deleteOne: f('mutation', gqlNames.deleteMutationName),
    deleteMany: f('mutation', gqlNames.deleteManyMutationName)
  };
}

const DEFAULT_BASE_URL$1 = '/images';
const DEFAULT_IMAGES_STORAGE_PATH = './public/images';

const getImageMetadataFromBuffer = async buffer => {
  const filesize = buffer.length;
  const fileType = fromBuffer(buffer);

  if (!fileType) {
    throw new Error('File type not found');
  }

  const extension = fileType.ext;

  if (extension !== 'jpg' && extension !== 'png' && extension !== 'webp' && extension !== 'gif') {
    throw new Error(`${extension} is not a supported image type`);
  }

  const {
    height,
    width
  } = imageSize(buffer);

  if (width === undefined || height === undefined) {
    throw new Error('Height and width could not be found for image');
  }

  return {
    width,
    height,
    filesize,
    extension
  };
};

function createImagesContext(config, cloudAssets) {
  if (!config.images) {
    return;
  }

  const {
    images
  } = config;
  const {
    baseUrl = DEFAULT_BASE_URL$1,
    storagePath = DEFAULT_IMAGES_STORAGE_PATH
  } = images.local || {};

  if (images.upload === 'local') {
    fs__default.mkdirSync(storagePath, {
      recursive: true
    });
  }

  return {
    getUrl: async (mode, id, extension) => {
      if (mode === 'cloud') {
        return cloudAssets().images.url(id, extension);
      }

      const filename = `${id}.${extension}`;
      return `${baseUrl}/${filename}`;
    },
    getDataFromRef: async ref => {
      const imageRef = parseImageRef(ref);

      if (!imageRef) {
        throw new Error('Invalid image reference');
      }

      const {
        mode
      } = imageRef;

      if (mode === 'cloud') {
        const metadata = await cloudAssets().images.metadata(imageRef.id, imageRef.extension);
        return _objectSpread(_objectSpread({}, imageRef), metadata);
      }

      const buffer = await fs__default.readFile(path__default.join(storagePath, `${imageRef.id}.${imageRef.extension}`));
      const metadata = await getImageMetadataFromBuffer(buffer);
      return _objectSpread(_objectSpread({}, imageRef), metadata);
    },
    getDataFromStream: async stream => {
      const {
        upload: mode
      } = images;
      const id = v4();

      if (mode === 'cloud') {
        const cloudMetadata = await cloudAssets().images.upload(stream, id);
        return _objectSpread({
          mode,
          id
        }, cloudMetadata);
      }

      const chunks = [];

      for await (let chunk of stream) {
        chunks.push(chunk);
      }

      const buffer = Buffer.concat(chunks);
      const metadata = await getImageMetadataFromBuffer(buffer);
      await fs__default.writeFile(path__default.join(storagePath, `${id}.${metadata.extension}`), buffer);
      return _objectSpread({
        mode,
        id
      }, metadata);
    }
  };
}

const DEFAULT_BASE_URL = '/files';
const DEFAULT_FILES_STORAGE_PATH = './public/files';

const defaultTransformer = str => slugify(str);

const generateSafeFilename = function (filename) {
  let transformFilename = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : defaultTransformer;
  // Appends a UUID to the filename so that people can't brute-force guess stored filenames
  //
  // This regex lazily matches for any characters that aren't a new line
  // it then optionally matches the last instance of a "." symbol
  // followed by any alphanumerical character before the end of the string
  const [, name, ext] = filename.match(/^([^:\n].*?)(\.[A-Za-z0-9]+)?$/);
  const id = crypto.randomBytes(24).toString('base64').replace(/[^a-zA-Z0-9]/g, '').slice(12); // console.log(id, id.length, id.slice(12).length);

  const urlSafeName = filenamify(transformFilename(name), {
    maxLength: 100 - id.length,
    replacement: '-'
  });

  if (ext) {
    return `${urlSafeName}-${id}${ext}`;
  }

  return `${urlSafeName}-${id}`;
};

function createFilesContext(config, cloudAssets) {
  if (!config.files) {
    return;
  }

  const {
    files
  } = config;
  const {
    baseUrl = DEFAULT_BASE_URL,
    storagePath = DEFAULT_FILES_STORAGE_PATH
  } = files.local || {};

  if (files.upload === 'local') {
    fs__default.mkdirSync(storagePath, {
      recursive: true
    });
  }

  return {
    getUrl: async (mode, filename) => {
      if (mode === 'cloud') {
        return cloudAssets().files.url(filename);
      }

      return `${baseUrl}/${filename}`;
    },
    getDataFromRef: async ref => {
      const fileRef = parseFileRef(ref);

      if (!fileRef) {
        throw new Error('Invalid file reference');
      }

      const {
        mode,
        filename
      } = fileRef;

      if (mode === 'cloud') {
        const {
          filesize
        } = await cloudAssets().files.metadata(filename);
        return _objectSpread({
          filesize
        }, fileRef);
      }

      const {
        size: filesize
      } = await fs__default.stat(path__default.join(storagePath, fileRef.filename));
      return _objectSpread({
        filesize
      }, fileRef);
    },
    getDataFromStream: async (stream, originalFilename) => {
      const {
        upload: mode
      } = files;
      const filename = generateSafeFilename(originalFilename, files.transformFilename);

      if (mode === 'cloud') {
        const {
          filesize
        } = await cloudAssets().files.upload(stream, filename);
        return {
          mode,
          filesize,
          filename
        };
      }

      const writeStream = fs__default.createWriteStream(path__default.join(storagePath, filename));
      const pipeStreams = new Promise((resolve, reject) => {
        pipeline(stream, writeStream, err => {
          if (err) {
            reject(err);
          } else {
            resolve();
          }
        });
      });

      try {
        await pipeStreams;
        const {
          size: filesize
        } = await fs__default.stat(path__default.join(storagePath, filename));
        return {
          mode,
          filesize,
          filename
        };
      } catch (e) {
        await fs__default.remove(path__default.join(storagePath, filename));
        throw e;
      }
    }
  };
}

function makeCreateContext(_ref) {
  let {
    graphQLSchema,
    sudoGraphQLSchema,
    prismaClient,
    gqlNamesByList,
    config,
    lists,
    cloudAssetsAPI
  } = _ref;
  const images = createImagesContext(config, cloudAssetsAPI);
  const files = createFilesContext(config, cloudAssetsAPI); // We precompute these helpers here rather than every time createContext is called
  // because they involve creating a new GraphQLSchema, creating a GraphQL document AST(programmatically, not by parsing) and validating the
  // note this isn't as big of an optimisation as you would imagine(at least in comparison with the rest of the system),
  // the regular non-db lists api does more expensive things on every call
  // like parsing the generated GraphQL document, and validating it against the schema on _every_ call
  // is that really that bad? no not really. this has just been more optimised because the cost of what it's
  // doing is more obvious(even though in reality it's much smaller than the alternative)

  const publicDbApiFactories = {};

  for (const [listKey, gqlNames] of Object.entries(gqlNamesByList)) {
    publicDbApiFactories[listKey] = getDbAPIFactory(gqlNames, graphQLSchema);
  }

  const sudoDbApiFactories = {};

  for (const [listKey, gqlNames] of Object.entries(gqlNamesByList)) {
    sudoDbApiFactories[listKey] = getDbAPIFactory(gqlNames, sudoGraphQLSchema);
  }

  const createContext = function () {
    var _config$graphql$query, _config$graphql, _config$graphql$query2, _config$experimental;

    let {
      sessionContext,
      sudo = false,
      req
    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
    const schema = sudo ? sudoGraphQLSchema : graphQLSchema;

    const rawGraphQL = _ref2 => {
      let {
        query,
        variables
      } = _ref2;
      const source = typeof query === 'string' ? query : print(query);
      return Promise.resolve(graphql$1({
        schema,
        source,
        contextValue: contextToReturn,
        variableValues: variables
      }));
    };

    const runGraphQL = async _ref3 => {
      var _result$errors;

      let {
        query,
        variables
      } = _ref3;
      let result = await rawGraphQL({
        query,
        variables
      });

      if ((_result$errors = result.errors) !== null && _result$errors !== void 0 && _result$errors.length) {
        throw result.errors[0];
      }

      return result.data;
    };

    const dbAPI = {};
    const itemAPI = {};

    const contextToReturn = _objectSpread(_objectSpread({
      db: dbAPI,
      query: itemAPI,
      totalResults: 0,
      prisma: prismaClient,
      graphql: {
        raw: rawGraphQL,
        run: runGraphQL,
        schema
      },
      maxTotalResults: (_config$graphql$query = (_config$graphql = config.graphql) === null || _config$graphql === void 0 ? void 0 : (_config$graphql$query2 = _config$graphql.queryLimits) === null || _config$graphql$query2 === void 0 ? void 0 : _config$graphql$query2.maxTotalResults) !== null && _config$graphql$query !== void 0 ? _config$graphql$query : Infinity,
      sudo: () => createContext({
        sessionContext,
        sudo: true,
        req
      }),
      exitSudo: () => createContext({
        sessionContext,
        sudo: false,
        req
      }),
      withSession: session => createContext({
        sessionContext: _objectSpread(_objectSpread({}, sessionContext), {}, {
          session
        }),
        sudo,
        req
      }),
      req
    }, sessionContext), {}, {
      // Note: This field lets us use the server-side-graphql-client library.
      // We may want to remove it once the updated itemAPI w/ query is available.
      gqlNames: listKey => gqlNamesByList[listKey],
      images,
      files
    });

    if ((_config$experimental = config.experimental) !== null && _config$experimental !== void 0 && _config$experimental.contextInitialisedLists) {
      contextToReturn.experimental = {
        initialisedLists: lists
      };
    }

    const dbAPIFactories = sudo ? sudoDbApiFactories : publicDbApiFactories;

    for (const listKey of Object.keys(gqlNamesByList)) {
      dbAPI[listKey] = dbAPIFactories[listKey](contextToReturn);
      itemAPI[listKey] = itemAPIForList(listKey, contextToReturn);
    }

    return contextToReturn;
  };

  return createContext;
}

function formUploadBody(_ref) {
  let {
    fieldName,
    fileName,
    data
  } = _ref;
  const form = new FormData();
  form.append(fieldName, data, fileName);
  return form;
}

const cloudAssetsConfigCache = new Map();
async function getCloudAssetsAPI(_ref2) {
  let {
    apiKey
  } = _ref2;
  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'x-keystone-version': `TODO 6 RC`
  };

  if (!cloudAssetsConfigCache.has(apiKey)) {
    const res = await fetch('https://init.keystonejs.cloud/api/rest/config', {
      headers
    });

    if (!res.ok) {
      throw new Error(`Failed to load cloud config: ${res.status}\n${await res.text()}`);
    }

    const json = await res.json();
    cloudAssetsConfigCache.set(apiKey, json);
  }

  const {
    // project,
    assets
  } = cloudAssetsConfigCache.get(apiKey);
  const {
    fileGetUrl,
    // fileDownloadUrl,
    fileUploadUrl,
    fileMetaUrl,
    imageGetUrl,
    imageUploadUrl,
    imageMetaUrl
  } = assets;
  return {
    images: {
      url(id, extension) {
        return `${imageGetUrl}/${id}.${extension}`;
      },

      async metadata(id, extension) {
        const res = await fetch(`${imageMetaUrl}/${id}.${extension}`);

        if (!res.ok) {
          console.error(`${res.status} ${await res.text()}`);
          throw new Error('Error occurred when fetching image metadata');
        }

        const metadata = await res.json();
        return {
          extension: metadata.extension,
          height: metadata.height,
          width: metadata.width,
          filesize: metadata.filesize
        };
      },

      async upload(buffer, id) {
        const res = await fetch(imageUploadUrl, {
          method: 'POST',
          body: formUploadBody({
            data: buffer,
            fieldName: 'image',
            fileName: id
          }),
          headers
        });

        if (!res.ok) {
          console.error(`${res.status} ${await res.text()}`);
          throw new Error('Error occurred when uploading image');
        }

        const metadata = await res.json();
        return {
          extension: metadata.extension,
          filesize: metadata.filesize,
          height: metadata.height,
          width: metadata.width
        };
      }

    },
    files: {
      url(filename) {
        return `${fileGetUrl}/${filename}`;
      },

      async metadata(filename) {
        const res = await fetch(`${fileMetaUrl}/${filename}`);

        if (!res.ok) {
          console.error(`${res.status} ${await res.text()}`);
          throw new Error('Error occurred when fetching file metadata');
        }

        const metadata = await res.json();
        return {
          mode: 'cloud',
          filesize: metadata.filesize,
          filename
        };
      },

      async upload(stream, filename) {
        const res = await fetch(fileUploadUrl, {
          method: 'POST',
          body: formUploadBody({
            data: stream,
            fieldName: 'file',
            fileName: filename
          }),
          headers
        });

        if (!res.ok) {
          console.error(`${res.status} ${await res.text()}`);
          throw new Error('Error occurred when uploading file');
        }

        const metadata = await res.json();
        return {
          mode: 'cloud',
          filesize: metadata.filesize,
          filename
        };
      }

    }
  };
}

function getSudoGraphQLSchema(config) {
  // This function creates a GraphQLSchema based on a modified version of the provided config.
  // The modifications are:
  //  * All list level access control is disabled
  //  * All field level access control is disabled
  //  * All graphql.omit configuration is disabled
  //  * All fields are explicitly made filterable and orderable
  //
  // These changes result in a schema without any restrictions on the CRUD
  // operations that can be run.
  //
  // The resulting schema is used as the GraphQL schema when calling `context.sudo()`.
  const transformedConfig = _objectSpread(_objectSpread({}, config), {}, {
    ui: _objectSpread(_objectSpread({}, config.ui), {}, {
      isAccessAllowed: () => true
    }),
    lists: Object.fromEntries(Object.entries(config.lists).map(_ref => {
      let [listKey, list] = _ref;
      return [listKey, _objectSpread(_objectSpread({}, list), {}, {
        access: {
          operation: {},
          item: {},
          filter: {}
        },
        graphql: _objectSpread(_objectSpread({}, list.graphql || {}), {}, {
          omit: []
        }),
        fields: Object.fromEntries(Object.entries(list.fields).map(_ref2 => {
          let [fieldKey, field] = _ref2;
          return [fieldKey, data => {
            const f = field(data);
            return _objectSpread(_objectSpread({}, f), {}, {
              access: () => true,
              isFilterable: true,
              isOrderable: true,
              graphql: _objectSpread(_objectSpread({}, f.graphql || {}), {}, {
                omit: []
              })
            });
          }];
        }))
      })];
    }))
  });

  const lists = initialiseLists(transformedConfig);
  const adminMeta = createAdminMeta(transformedConfig, lists);
  return createGraphQLSchema(transformedConfig, lists, adminMeta);
}

function createSystem(config, isLiveReload) {
  const lists = initialiseLists(config);
  const adminMeta = createAdminMeta(config, lists);
  const graphQLSchema = createGraphQLSchema(config, lists, adminMeta);
  const sudoGraphQLSchema = getSudoGraphQLSchema(config);
  return {
    graphQLSchema,
    adminMeta,
    getKeystone: PrismaClient => {
      const prismaClient = new PrismaClient({
        log: config.db.enableLogging ? ['query'] : undefined,
        datasources: {
          [config.db.provider]: {
            url: config.db.url
          }
        }
      });
      setWriteLimit(prismaClient, pLimit(config.db.provider === 'sqlite' ? 1 : Infinity));
      prismaClient.$on('beforeExit', async () => {
        var _prismaClient$_engine;

        // Prisma is failing to properly clean up its child processes
        // https://github.com/keystonejs/keystone/issues/5477
        // We explicitly send a SIGINT signal to the prisma child process on exit
        // to ensure that the process is cleaned up appropriately.
        (_prismaClient$_engine = prismaClient._engine.child) === null || _prismaClient$_engine === void 0 ? void 0 : _prismaClient$_engine.kill('SIGINT');
      });
      let cloudAssetsAPI = undefined;
      const createContext = makeCreateContext({
        graphQLSchema,
        sudoGraphQLSchema,
        config,
        prismaClient,
        gqlNamesByList: Object.fromEntries(Object.entries(lists).map(_ref3 => {
          let [listKey, list] = _ref3;
          return [listKey, getGqlNames(list)];
        })),
        lists,
        cloudAssetsAPI: () => {
          if (cloudAssetsAPI === undefined) {
            throw new Error('Keystone Cloud config was not loaded');
          }

          return cloudAssetsAPI;
        }
      });
      return {
        async connect() {
          var _config$experimental, _config$experimental$;

          if (!isLiveReload) {
            var _config$db$onConnect, _config$db;

            await prismaClient.$connect();
            const context = createContext({
              sudo: true
            });
            await ((_config$db$onConnect = (_config$db = config.db).onConnect) === null || _config$db$onConnect === void 0 ? void 0 : _config$db$onConnect.call(_config$db, context));
          }

          if ((_config$experimental = config.experimental) !== null && _config$experimental !== void 0 && (_config$experimental$ = _config$experimental.cloud) !== null && _config$experimental$ !== void 0 && _config$experimental$.apiKey) {
            try {
              cloudAssetsAPI = await getCloudAssetsAPI({
                apiKey: config.experimental.cloud.apiKey
              });
            } catch (err) {
              console.error('failed to connect to Keystone Cloud', err);
            }
          }
        },

        async disconnect() {
          await prismaClient.$disconnect();
        },

        createContext
      };
    }
  };
}

const views = path__default.join(packagePath, '___internal-do-not-use-will-break-in-patch/admin-ui/id-field-view');
const idParsers = {
  autoincrement(val) {
    if (val === null) {
      throw userInputError('Only an integer can be passed to id filters');
    }

    const parsed = parseInt(val);

    if (Number.isInteger(parsed)) {
      return parsed;
    }

    throw userInputError('Only an integer can be passed to id filters');
  },

  cuid(val) {
    // isCuid is just "it's a string and it starts with c"
    // https://github.com/ericelliott/cuid/blob/215b27bdb78d3400d4225a4eeecb3b71891a5f6f/index.js#L69-L73
    if (typeof val === 'string' && isCuid(val)) {
      return val;
    }

    throw userInputError('Only a cuid can be passed to id filters');
  },

  uuid(val) {
    if (typeof val === 'string' && validate$1(val)) {
      return val.toLowerCase();
    }

    throw userInputError('Only a uuid can be passed to id filters');
  }

};
const nonCircularFields = {
  equals: arg({
    type: ID
  }),
  in: arg({
    type: list(nonNull(ID))
  }),
  notIn: arg({
    type: list(nonNull(ID))
  }),
  lt: arg({
    type: ID
  }),
  lte: arg({
    type: ID
  }),
  gt: arg({
    type: ID
  }),
  gte: arg({
    type: ID
  })
};
const IDFilter = inputObject({
  name: 'IDFilter',
  fields: () => _objectSpread(_objectSpread({}, nonCircularFields), {}, {
    not: arg({
      type: IDFilter
    })
  })
});
const filterArg = arg({
  type: IDFilter
});

function resolveVal(input, kind) {
  if (input === null) {
    throw userInputError('id filter cannot be null');
  }

  const idParser = idParsers[kind];
  const obj = {};

  for (const key of ['equals', 'gt', 'gte', 'lt', 'lte']) {
    const val = input[key];

    if (val !== undefined) {
      const parsed = idParser(val);
      obj[key] = parsed;
    }
  }

  for (const key of ['in', 'notIn']) {
    const val = input[key];

    if (val !== undefined) {
      if (val === null) {
        throw userInputError(`${key} id filter cannot be null`);
      }

      obj[key] = val.map(x => idParser(x));
    }
  }

  if (input.not !== undefined) {
    obj.not = resolveVal(input.not, kind);
  }

  return obj;
}

const idFieldType = config => meta => {
  const parseVal = idParsers[config.kind];
  return fieldType({
    kind: 'scalar',
    mode: 'required',
    scalar: config.kind === 'autoincrement' ? 'Int' : 'String',
    nativeType: meta.provider === 'postgresql' && config.kind === 'uuid' ? 'Uuid' : undefined,
    default: {
      kind: config.kind
    }
  })(_objectSpread(_objectSpread({}, config), {}, {
    // The ID field is always filterable and orderable.
    isFilterable: true,
    isOrderable: true,
    input: {
      where: {
        arg: filterArg,

        resolve(val) {
          return resolveVal(val, config.kind);
        }

      },
      uniqueWhere: {
        arg: arg({
          type: ID
        }),
        resolve: parseVal
      },
      orderBy: {
        arg: arg({
          type: orderDirectionEnum
        })
      }
    },
    output: field({
      type: nonNull(ID),

      resolve(_ref) {
        let {
          value
        } = _ref;
        return value.toString();
      }

    }),
    views,
    getAdminMeta: () => ({
      kind: config.kind
    }),
    ui: {
      createView: {
        fieldMode: 'hidden'
      },
      itemView: {
        fieldMode: 'hidden'
      }
    }
  }));
};

/* Validate lists config and default the id field */

function applyIdFieldDefaults(config) {
  var _config$db$idField;

  const lists = {};
  const defaultIdField = (_config$db$idField = config.db.idField) !== null && _config$db$idField !== void 0 ? _config$db$idField : {
    kind: 'cuid'
  };
  Object.keys(config.lists).forEach(key => {
    var _listConfig$db$idFiel, _listConfig$db;

    const listConfig = config.lists[key];

    if (listConfig.fields.id) {
      throw new Error(`A field with the \`id\` path is defined in the fields object on the ${JSON.stringify(key)} list. This is not allowed, use the idField option instead.`);
    }

    const idField = idFieldType((_listConfig$db$idFiel = (_listConfig$db = listConfig.db) === null || _listConfig$db === void 0 ? void 0 : _listConfig$db.idField) !== null && _listConfig$db$idFiel !== void 0 ? _listConfig$db$idFiel : defaultIdField);

    const fields = _objectSpread({
      id: idField
    }, listConfig.fields);

    lists[key] = _objectSpread(_objectSpread({}, listConfig), {}, {
      fields
    });
  });
  return lists;
}

/*
  This function executes the validation and other initialisation logic that
  needs to be run on Keystone Config before it can be used.
*/

function initConfig(config) {
  if (!['postgresql', 'sqlite'].includes(config.db.provider)) {
    throw new Error('Invalid db configuration. Please specify db.provider as either "sqlite" or "postgresql"');
  }

  return _objectSpread(_objectSpread({}, config), {}, {
    lists: applyIdFieldDefaults(config)
  });
}

export { DEFAULT_FILES_STORAGE_PATH as D, DEFAULT_IMAGES_STORAGE_PATH as a, createSystem as c, generateAdminUI as g, initConfig as i, serializePathForImport as s, writeAdminFile as w };
